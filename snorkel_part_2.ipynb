{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virus-Host Species Relation Extraction\n",
    "## Notebook 2\n",
    "### UC Davis Epicenter for Disease Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "VirusHost = candidate_subclass('VirusHost', ['virus', 'host'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Writing Labeling Functions\n",
    "\n",
    "Labeling functions encode our heuristics and weak supervision signals to generate (noisy) labels for our training candidates.\n",
    "\n",
    "In Snorkel, our primary interface through which we provide training signal to the end extraction model we are training is by writing **labeling functions (LFs)** (as opposed to hand-labeling massive training sets). \n",
    "\n",
    "A labeling function is just a Python function that accepts a `Candidate` and returns `1` to mark the `Candidate` as true, `-1` to mark the `Candidate` as false, and `0` to abstain from labeling the `Candidate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, \n",
    "    get_right_tokens, \n",
    "    get_between_tokens,\n",
    "    get_text_between, \n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing labels\n",
    "train_cands = session.query(VirusHost).filter(VirusHost.split == 0).order_by(VirusHost.id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VirusHost(Span(\"b'USUV'\", sentence=18189, chars=[94,97], words=[17,17]), Span(\"b'Cygnus olor'\", sentence=18189, chars=[138,148], words=[25,26]))\n",
      "Sentence(Document vbz.2014.1746.pdf,181,b'Bird\\xe2\\x80\\x99s order Bird\\xe2\\x80\\x99s name Scientific name Migration pattern Samples tested WNV positive (ND50) USUV positive (ND50) Anseriformes Mute Swan Cygnus olor S 18 2 (10130), 2a 0, 2a Pelecaniformes Grey Heron Ardea cinerea R, P, S, L 10 1 (10) 0 Ciconiiformes White Stork Ciconia ciconia L 7 2 (10,30) 1 (15) Accipitriformes Osprey Pandion haliaetus L 6 2 (10,320) 1 (40) Western Marsh Harrier Circus aeruginosus L 4 1 (10) 0 Northern Goshawk Accipiter gentilis R, P 25 2 (10,20), 1b 0 Eurasian Sparrow Hawk Accipiter nisus P, S 33 2 (10) 0 Common Buzzard Buteo buteo P, S 100 6 (10\\xe2\\x80\\x9320) 1 (10) Falconiformes Common Kestrel Falco tinnunculus P, S 56 9 (10\\xe2\\x80\\x93120) 1 (20), 2 (20,30) Gruiformes Eurasian Coot Fulica atra P, S 4 2 (15\\xe2\\x80\\x93120) 1 (40) Columbiformes Feral Common Pigeon Columba livia f. domestica R, P 43 2 (10) 0 Common Wood Pigeon Columba palumbus R, P, S 40 2 (10, 80), 1b 0 Pigeon Columba sp.')\n",
      "Candidate LEFT tokens:   \t ['order', 'bird', '’s', 'name', 'scientific', 'name', 'migration', 'pattern', 'samples', 'tested', 'wnv', 'positive', '(', 'nd50', ')']\n",
      "Candidate RIGHT tokens:  \t ['s', '18', '2', '(', '10130', ')', ',', '2a', '0', ',', '2a', 'pelecaniformes', 'grey', 'heron', 'ardea']\n",
      "Candidate BETWEEN tokens:\t  positive (ND50) Anseriformes Mute Swan \n",
      "Get tagged text:\t Bird’s order Bird’s name Scientific name Migration pattern Samples tested WNV positive (ND50) {{A}} positive (ND50) Anseriformes Mute Swan {{B}} S 18 2 (10130), 2a 0, 2a Pelecaniformes Grey Heron Ardea cinerea R, P, S, L 10 1 (10) 0 Ciconiiformes White Stork Ciconia ciconia L 7 2 (10,30) 1 (15) Accipitriformes Osprey Pandion haliaetus L 6 2 (10,320) 1 (40) Western Marsh Harrier Circus aeruginosus L 4 1 (10) 0 Northern Goshawk Accipiter gentilis R, P 25 2 (10,20), 1b 0 Eurasian Sparrow Hawk Accipiter nisus P, S 33 2 (10) 0 Common Buzzard Buteo buteo P, S 100 6 (10–20) 1 (10) Falconiformes Common Kestrel Falco tinnunculus P, S 56 9 (10–120) 1 (20), 2 (20,30) Gruiformes Eurasian Coot Fulica atra P, S 4 2 (15–120) 1 (40) Columbiformes Feral Common Pigeon Columba livia f. domestica R, P 43 2 (10) 0 Common Wood Pigeon Columba palumbus R, P, S 40 2 (10, 80), 1b 0 Pigeon Columba sp.\n"
     ]
    }
   ],
   "source": [
    "# choose a candidate for testing; can test different functions and regex rules here\n",
    "print(train_cands[140])\n",
    "sentence = train_cands[140].get_parent()  # get one exmaple sentence to test\n",
    "document = sentence.get_parent()\n",
    "print(sentence)\n",
    "print(\"Candidate LEFT tokens:   \\t\", list(get_left_tokens(train_cands[140],window=15)))\n",
    "print(\"Candidate RIGHT tokens:  \\t\", list(get_right_tokens(train_cands[140],window=15)))\n",
    "print(\"Candidate BETWEEN tokens:\\t\", get_text_between(train_cands[140]))\n",
    "print(\"Get tagged text:\\t\", get_tagged_text(train_cands[140]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Pattern based labeling functions, which look for certain keywords\n",
    "\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "# Positive LFs:\n",
    "\n",
    "detect = {'detect', 'detects', 'detected', 'detecting', 'detection', 'detectable'}\n",
    "detect_l = ['detect', 'detects', 'detected', 'detecting', 'detection', 'detectable']\n",
    "infect = {'infect', 'infects', 'infected', 'infecting', 'infection'}\n",
    "isolate = {'isolate', 'isolates', 'isolated', 'isolating', 'isolation'}\n",
    "other_verbs = {\n",
    "    'transmit(ted)?', 'found', 'find(ings)?', 'affect(s|ed|ing)?', 'confirm(s|ed|ing)?', 'relat(ed|es|e|ing|ion)?', 'recovered', 'identified',\n",
    "}\n",
    "misc = {\n",
    "    'seropositive', 'seropositivity', '\\ssero.*', 'positive', 'host(s)?', 'prevalen(ce|t)?', 'case(s)?', 'ELISA', 'titer', 'viremia', 'antibod(y|ies)?', 'antigen', 'exposure', 'PCR', 'polymerase chain reaction', 'RNA', 'DNA', 'nucleotide', 'sequence', 'evidence', 'common', 'success(fully)?', 'extract(ed)?', 'PFU', '(PFU)', 'plaque-forming unit'\n",
    "}\n",
    "\n",
    "causal = ['caus(es|ed|e|ing|ation)?', 'induc(es|ed|e|ing)?', 'associat(ed|ing|es|e|ion)?']\n",
    "\n",
    "positive = {'detect', 'detects', 'detected', 'detecting', 'detection', 'detectable', 'infect', 'infects', 'infected', 'infecting', 'infection', 'isolate', 'isolates', 'isolated', 'isolating', 'isolation'}\n",
    "positive_l = ['detect', 'detects', 'detected', 'detecting', 'detection', 'detectable', 'infect', 'infects', 'infected', 'infecting', 'infection', 'isolate', 'isolates', 'isolated', 'isolating', 'isolation']\n",
    "\n",
    "# negative words\n",
    "negative = {\n",
    "    'negative (antibodies)?', 'negate', 'not', 'Not', '\\sno\\s', '(titer\\W+(?:\\w+\\W+){1,6}?less than)', 'none', 'resist', 'never'\n",
    "}\n",
    "negative_l = [\n",
    "    'negative (antibodies)?', 'negate', 'not', 'Not', '\\sno\\s', '(titer\\W+(?:\\w+\\W+){1,6}?less than)', 'none', 'resist', 'never'\n",
    "]\n",
    "neg_rgx = r'|'.join(negative_l)\n",
    "\n",
    "# search nearby words for negatives, returns True if negative word found:\n",
    "def neg_nearby(c):  \n",
    "    if (len(negative.intersection(get_between_tokens(c))) > 0):\n",
    "        return True\n",
    "    elif (len(negative.intersection(get_left_tokens(c, window=10))) > 0):\n",
    "        return True\n",
    "    elif (len(negative.intersection(get_right_tokens(c, window=10))) > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# words like detect \n",
    "def LF_detect(c):\n",
    "    if (len(detect.intersection(get_between_tokens(c))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(detect.intersection(get_left_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(detect.intersection(get_left_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(detect.intersection(get_right_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(detect.intersection(get_right_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def LF_infect(c):\n",
    "    if len(infect.intersection(get_between_tokens(c))) > 0  and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(infect.intersection(get_left_tokens(c[0], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(infect.intersection(get_left_tokens(c[1], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(infect.intersection(get_right_tokens(c[0], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(infect.intersection(get_right_tokens(c[1], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    # Words like 'isolated'\n",
    "def LF_isolate(c):\n",
    "    if len(isolate.intersection(get_between_tokens(c))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(isolate.intersection(get_left_tokens(c[0], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(isolate.intersection(get_left_tokens(c[1], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(isolate.intersection(get_right_tokens(c[0], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(isolate.intersection(get_right_tokens(c[1], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "        \n",
    "def LF_misc(c):\n",
    "    if (len(misc.intersection(get_between_tokens(c))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(misc.intersection(get_left_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(misc.intersection(get_left_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(misc.intersection(get_right_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(misc.intersection(get_right_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# terms like 'virus A caused disease in host B'\n",
    "def LF_v_cause_h(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,50}(not|no|negative).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "# if candidates are nearby and check for negative words\n",
    "def LF_v_h(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,200}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search(neg_rgx, get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "def LF_h_v(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{B}}.{0,250}{{A}}', get_tagged_text(c), re.I)\n",
    "        and not re.search(neg_rgx, get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "# positive verbs (detect, infect, isolate)\n",
    "def LF_positive(c):\n",
    "    if (len(positive.intersection(get_between_tokens(c))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(positive.intersection(get_left_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(positive.intersection(get_left_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(positive.intersection(get_right_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(positive.intersection(get_right_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def LF_positive2(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,100} ' + ltp(positive_l) + '.{0,100}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,100}(not|no|negative).{0,20}' + ltp(positive_l) + '.{0,100}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "def LF_other_verbs(c):\n",
    "    if (len(other_verbs.intersection(get_between_tokens(c))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(other_verbs.intersection(get_left_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(other_verbs.intersection(get_left_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(other_verbs.intersection(get_right_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(other_verbs.intersection(get_right_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def LF_percents(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,100}' + '\\d+%|\\d+(.)?\\d+%' + '.{0,100}{{B}}', get_tagged_text(c), re.I) \n",
    "        and not re.search('(none|not|\\W+no\\W+|humidity)', get_text_between(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "\n",
    "# Negative LFs:\n",
    "\n",
    "# Uncertain pairs\n",
    "uncertain = ['combin', 'possible', 'unlikely']\n",
    "\n",
    "def LF_uncertain(c):\n",
    "    return rule_regex_search_before_A(c, ltp(uncertain) + '.*', -1)\n",
    "\n",
    "# if candidate pair is too far apart (between 200-5000 characs apart), mark as negative\n",
    "def LF_far_v_h(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{250,5000}', -1)\n",
    "\n",
    "def LF_far_h_v(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{250,5000}', -1)\n",
    "\n",
    "def LF_neg_h(c):\n",
    "    return -1 if re.search(neg_rgx + '.{0,100}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_neg_assertions(c):\n",
    "    if (len(negative.intersection(get_between_tokens(c))) > 0): \n",
    "        return -1\n",
    "    elif (len(negative.intersection(get_left_tokens(c[0], window=20))) > 0):\n",
    "        return -1\n",
    "    elif (len(negative.intersection(get_left_tokens(c[1], window=20))) > 0):\n",
    "        return -1\n",
    "    elif (len(negative.intersection(get_right_tokens(c[0], window=20))) > 0):\n",
    "        return -1\n",
    "    elif (len(negative.intersection(get_right_tokens(c[1], window=20))) > 0):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distant Supervision LFs\n",
    "# Compare candidates with a database of known virus-host pairs (from Virus-Host Database)\n",
    "\n",
    "import bz2\n",
    "\n",
    "# Function to remove special characters from text\n",
    "def strip_special(s):\n",
    "    return ''.join(c for c in s if ord(c) < 128)\n",
    "\n",
    "# Read in known pairs and save as set of tuples\n",
    "with bz2.BZ2File('virushostdb.tar.bz2', 'rb') as f:\n",
    "    known_pairs = set(\n",
    "        tuple(strip_special(x.decode('utf-8')).strip().split('\\t')) for x in f.readlines()\n",
    "    )\n",
    "\n",
    "def LF_distant_supervision(c):\n",
    "    v, h = c.virus.get_span(), c.host.get_span()\n",
    "    return 1 if (v,h) in known_pairs else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all LFs\n",
    "LFs = [\n",
    "     LF_detect, LF_infect, LF_isolate, LF_positive, LF_positive2, LF_misc, LF_v_cause_h, LF_v_h, LF_h_v, LF_other_verbs, LF_uncertain, LF_far_v_h, LF_far_h_v, LF_neg_h, LF_distant_supervision, LF_neg_assertions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number labeled: 3752\n"
     ]
    }
   ],
   "source": [
    "# To label and view LFs for testing\n",
    "labeled = []\n",
    "for c in session.query(VirusHost).filter(VirusHost.split == 0).all():\n",
    "    for function in LFs:\n",
    "        if function(c) != 0:\n",
    "            if c not in labeled:\n",
    "                labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### To view only a specific LF\n",
    "\n",
    "labeled2 = []\n",
    "for c in session.query(VirusHost).filter(VirusHost.split == 0).all():\n",
    "    if LF_far_v_h(c) != 0: # change this line to test a specified LF\n",
    "        if c not in labeled2:\n",
    "            labeled2.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b7a1d27ea84385854407afe1e39903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SentenceNgramViewer(cids=[[[773, 1627, 2068, 2545, 2600], [2120, 2121], [468]], [[855, 1732], [0, 1], [239]], …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "SentenceNgramViewer(labeled, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Applying Labeling Functions\n",
    "\n",
    "We run the LFs over all training candidates, producing a set of Labels (Virus and Host) and LabelKeys (the names of the LFs) in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the label annotator class\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3808/3808 [00:20<00:00, 182.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3808x16 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 7663 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1701)\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the returned matrix is a special subclass of the `scipy.sparse.csr_matrix` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VirusHost(Span(\"b'WNV'\", sentence=4781, chars=[737,739], words=[201,201]), Span(\"b'Green woodpecker'\", sentence=4781, chars=[236,251], words=[63,64]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the candidate names and positions of any candidate in the set\n",
    "L_train.get_candidate(session, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelKey (LF_detect)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the LabelKey (the name of the LF used to identify the candidate)\n",
    "L_train.get_key(session, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing statistics about the resulting label matrix:\n",
    "\n",
    "* **Coverage** is the fraction of candidates that the labeling function emits a non-zero label for.\n",
    "* **Overlap** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for.\n",
    "* **Conflict** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a *conflicting* non-zero label for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_detect</th>\n",
       "      <td>0</td>\n",
       "      <td>0.060399</td>\n",
       "      <td>0.060399</td>\n",
       "      <td>0.016282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_infect</th>\n",
       "      <td>1</td>\n",
       "      <td>0.053046</td>\n",
       "      <td>0.053046</td>\n",
       "      <td>0.016544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_isolate</th>\n",
       "      <td>2</td>\n",
       "      <td>0.070378</td>\n",
       "      <td>0.070378</td>\n",
       "      <td>0.023372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive</th>\n",
       "      <td>3</td>\n",
       "      <td>0.163340</td>\n",
       "      <td>0.163340</td>\n",
       "      <td>0.046218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.045956</td>\n",
       "      <td>0.045956</td>\n",
       "      <td>0.008403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_misc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.243697</td>\n",
       "      <td>0.148897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_cause_h</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.005777</td>\n",
       "      <td>0.001313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_h</th>\n",
       "      <td>7</td>\n",
       "      <td>0.265231</td>\n",
       "      <td>0.138393</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_h_v</th>\n",
       "      <td>8</td>\n",
       "      <td>0.173845</td>\n",
       "      <td>0.061975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_other_verbs</th>\n",
       "      <td>9</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.043592</td>\n",
       "      <td>0.019695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003414</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_v_h</th>\n",
       "      <td>11</td>\n",
       "      <td>0.269958</td>\n",
       "      <td>0.233718</td>\n",
       "      <td>0.112920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_h_v</th>\n",
       "      <td>12</td>\n",
       "      <td>0.113183</td>\n",
       "      <td>0.091649</td>\n",
       "      <td>0.042805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_h</th>\n",
       "      <td>13</td>\n",
       "      <td>0.406513</td>\n",
       "      <td>0.327206</td>\n",
       "      <td>0.136029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_distant_supervision</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_assertions</th>\n",
       "      <td>15</td>\n",
       "      <td>0.084559</td>\n",
       "      <td>0.084559</td>\n",
       "      <td>0.012080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j  Coverage  Overlaps  Conflicts\n",
       "LF_detect                0  0.060399  0.060399   0.016282\n",
       "LF_infect                1  0.053046  0.053046   0.016544\n",
       "LF_isolate               2  0.070378  0.070378   0.023372\n",
       "LF_positive              3  0.163340  0.163340   0.046218\n",
       "LF_positive2             4  0.045956  0.045956   0.008403\n",
       "LF_misc                  5  0.252101  0.243697   0.148897\n",
       "LF_v_cause_h             6  0.005777  0.005777   0.001313\n",
       "LF_v_h                   7  0.265231  0.138393   0.003151\n",
       "LF_h_v                   8  0.173845  0.061975   0.000000\n",
       "LF_other_verbs           9  0.044118  0.043592   0.019695\n",
       "LF_uncertain            10  0.003414  0.003151   0.003151\n",
       "LF_far_v_h              11  0.269958  0.233718   0.112920\n",
       "LF_far_h_v              12  0.113183  0.091649   0.042805\n",
       "LF_neg_h                13  0.406513  0.327206   0.136029\n",
       "LF_distant_supervision  14  0.000525  0.000525   0.000000\n",
       "LF_neg_assertions       15  0.084559  0.084559   0.012080"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Checking Against Gold Labels (Hand Labeled Set)\n",
    "- Run the labeler on the development set\n",
    "- Load in some external labels:\n",
    "\n",
    "### Load Gold Labels\n",
    "Gold labels are a _small_ set of examples (here, a subset of our training set) which we label by hand and use to help us develop and refine labeling functions. Unlike the _test set_, which we do not look at and use for final evaluation, we can inspect the development set while writing labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<430x1 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 126 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name = \"gold\", split=1)\n",
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 430/430 [00:02<00:00, 153.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%time L_dev = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericaxia3\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\snorkel\\annotations.py:137: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ac = (tp+tn) / (tp+tn+fp+fn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_detect</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_infect</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025581</td>\n",
       "      <td>0.025581</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_isolate</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive</th>\n",
       "      <td>3</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_misc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.190698</td>\n",
       "      <td>0.183721</td>\n",
       "      <td>0.097674</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_cause_h</th>\n",
       "      <td>6</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_h</th>\n",
       "      <td>7</td>\n",
       "      <td>0.248837</td>\n",
       "      <td>0.076744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_h_v</th>\n",
       "      <td>8</td>\n",
       "      <td>0.262791</td>\n",
       "      <td>0.083721</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_other_verbs</th>\n",
       "      <td>9</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_v_h</th>\n",
       "      <td>11</td>\n",
       "      <td>0.155814</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.030233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_h_v</th>\n",
       "      <td>12</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_h</th>\n",
       "      <td>13</td>\n",
       "      <td>0.090698</td>\n",
       "      <td>0.076744</td>\n",
       "      <td>0.048837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_distant_supervision</th>\n",
       "      <td>14</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_assertions</th>\n",
       "      <td>15</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j  Coverage  Overlaps  Conflicts  TP  FP  FN  TN  \\\n",
       "LF_detect                0  0.032558  0.032558   0.000000   6   3   0   0   \n",
       "LF_infect                1  0.025581  0.025581   0.002326   7   0   0   0   \n",
       "LF_isolate               2  0.002326  0.002326   0.000000   0   1   0   0   \n",
       "LF_positive              3  0.060465  0.060465   0.002326  13   4   0   0   \n",
       "LF_positive2             4  0.023256  0.023256   0.000000   4   1   0   0   \n",
       "LF_misc                  5  0.190698  0.183721   0.097674  22   5   0   0   \n",
       "LF_v_cause_h             6  0.004651  0.004651   0.000000   2   0   0   0   \n",
       "LF_v_h                   7  0.248837  0.076744   0.000000  30   8   0   0   \n",
       "LF_h_v                   8  0.262791  0.083721   0.002326  36   8   0   0   \n",
       "LF_other_verbs           9  0.034884  0.032558   0.004651   5   2   0   0   \n",
       "LF_uncertain            10  0.000000  0.000000   0.000000   0   0   0   0   \n",
       "LF_far_v_h              11  0.155814  0.032558   0.030233   0   0   2  19   \n",
       "LF_far_h_v              12  0.218605  0.034884   0.034884   0   0   1   5   \n",
       "LF_neg_h                13  0.090698  0.076744   0.048837   0   0  11   5   \n",
       "LF_distant_supervision  14  0.002326  0.002326   0.000000   0   0   0   0   \n",
       "LF_neg_assertions       15  0.032558  0.032558   0.006977   0   0   0   0   \n",
       "\n",
       "                        Empirical Acc.  \n",
       "LF_detect                     0.666667  \n",
       "LF_infect                     1.000000  \n",
       "LF_isolate                    0.000000  \n",
       "LF_positive                   0.764706  \n",
       "LF_positive2                  0.800000  \n",
       "LF_misc                       0.814815  \n",
       "LF_v_cause_h                  1.000000  \n",
       "LF_v_h                        0.789474  \n",
       "LF_h_v                        0.818182  \n",
       "LF_other_verbs                0.714286  \n",
       "LF_uncertain                       NaN  \n",
       "LF_far_v_h                    0.904762  \n",
       "LF_far_h_v                    0.833333  \n",
       "LF_neg_h                      0.312500  \n",
       "LF_distant_supervision             NaN  \n",
       "LF_neg_assertions                  NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Matrix Empirical Accuracies\n",
    "\n",
    "L_dev.lf_stats(session, labels=L_gold_dev.toarray().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Labeling Functions used:  16\n"
     ]
    }
   ],
   "source": [
    "print('Number of Labeling Functions used: ', len(LFs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating on Labeling Function Design:\n",
    "When writing labeling functions, you will want to iterate on the process outlined above several times. You should focus on tuning individual LFs, based on emprical accuracy metrics, and adding new LFs to improve coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### See Notebook Part 3 for Generative Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel-env)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
