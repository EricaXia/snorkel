{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virus-Host Species Relation Extraction\n",
    "## Notebook 2\n",
    "### UC Davis Epicenter for Disease Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "VirusHost = candidate_subclass('VirusHost', ['virus', 'host'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Writing Labeling Functions\n",
    "\n",
    "Labeling functions encode our heuristics and weak supervision signals to generate (noisy) labels for our training candidates.\n",
    "\n",
    "In Snorkel, our primary interface through which we provide training signal to the end extraction model we are training is by writing **labeling functions (LFs)** (as opposed to hand-labeling massive training sets). \n",
    "\n",
    "A labeling function is just a Python function that accepts a `Candidate` and returns `1` to mark the `Candidate` as true, `-1` to mark the `Candidate` as false, and `0` to abstain from labeling the `Candidate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, \n",
    "    get_right_tokens, \n",
    "    get_between_tokens,\n",
    "    get_text_between, \n",
    "    get_tagged_text,\n",
    "    rule_regex_search_tagged_text,\n",
    "    rule_regex_search_btw_AB,\n",
    "    rule_regex_search_btw_BA,\n",
    "    rule_regex_search_before_A,\n",
    "    rule_regex_search_before_B,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing labels\n",
    "train_cands = session.query(VirusHost).filter(VirusHost.split == 0).order_by(VirusHost.id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VirusHost(Span(\"b'duck circovirus'\", sentence=5191, chars=[1249,1263], words=[252,253]), Span(\"b'Muscovy duck'\", sentence=5191, chars=[1134,1145], words=[231,232]))\n",
      "Sentence(Document \"Cao-2011-Tembusu virus in ducks, china.pdf\",35,b'Author affi liations: Key Laboratory of Zoonosis of Ministry of Agriculture, Beijing, People\\xe2\\x80\\x99s Republic of China (Z. Cao, G. Ma, Dongdong Zhang, Dabing Zhang); China Agricultural University, Beijing (Z. Cao, G. Ma, Dongdong Zhang, Dabing Zhang); Zhejiang Academy of Agricultural Sciences, Hangzhou, People\\xe2\\x80\\x99s Republic of China (Cun Zhang, W. Ye); Beijing Academy of Agriculture and Forestry Sciences, Beijing (Y. Liu, J. Han); Beijing University of Agriculture, Beijing (F. Xu); Shandong Agricultural University, Taian, People\\xe2\\x80\\x99s Republic of China (X. Gao, Y. Tang, Y. Diao); Fujian Academy of Agricultural Sciences, Fuzhou, People\\xe2\\x80\\x99s Republic of China (S. Shi, C. Wan, Y. Huang); Chinese Center for Disease Control and Prevention, Beijing (Chen Zhang, B. He, M. Yang, X. Ma); and Yuyao Municipal Institute of Poultry Disease, Yuyao, People\\xe2\\x80\\x99s Republic of China (X. Lu) DOI: http://dx.doi.org/10.3201/eid1710.101890 was optimized by using the following controls, including nucleic acids extracted from theca folliculi of healthy Pekin ducks: avian infl uenza virus, Newcastle disease virus, egg drop syndrome virus, anatid herpesvirus 1, Muscovy duck parvovirus, goose parvovirus, duck reovirus, goose reovirus, duck hepatitis A virus, duck astrovirus, duck circovirus, and goose hemorrhagic polyomavirus.')\n",
      "Candidate LEFT tokens:   \t [',', 'duck', 'reovirus', ',', 'goose', 'reovirus', ',', 'duck', 'hepatitis', 'a', 'virus', ',', 'duck', 'astrovirus', ',']\n",
      "Candidate RIGHT tokens:  \t ['parvovirus', ',', 'goose', 'parvovirus', ',', 'duck', 'reovirus', ',', 'goose', 'reovirus', ',', 'duck', 'hepatitis', 'a', 'virus']\n",
      "Candidate BETWEEN tokens:\t  parvovirus, goose parvovirus, duck reovirus, goose reovirus, duck hepatitis A virus, duck astrovirus, \n",
      "Get tagged text:\t Author affi liations: Key Laboratory of Zoonosis of Ministry of Agriculture, Beijing, People’s Republic of China (Z. Cao, G. Ma, Dongdong Zhang, Dabing Zhang); China Agricultural University, Beijing (Z. Cao, G. Ma, Dongdong Zhang, Dabing Zhang); Zhejiang Academy of Agricultural Sciences, Hangzhou, People’s Republic of China (Cun Zhang, W. Ye); Beijing Academy of Agriculture and Forestry Sciences, Beijing (Y. Liu, J. Han); Beijing University of Agriculture, Beijing (F. Xu); Shandong Agricultural University, Taian, People’s Republic of China (X. Gao, Y. Tang, Y. Diao); Fujian Academy of Agricultural Sciences, Fuzhou, People’s Republic of China (S. Shi, C. Wan, Y. Huang); Chinese Center for Disease Control and Prevention, Beijing (Chen Zhang, B. He, M. Yang, X. Ma); and Yuyao Municipal Institute of Poultry Disease, Yuyao, People’s Republic of China (X. Lu) DOI: http://dx.doi.org/10.3201/eid1710.101890 was optimized by using the following controls, including nucleic acids extracted from theca folliculi of healthy Pekin ducks: avian infl uenza virus, Newcastle disease virus, egg drop syndrome virus, anatid herpesvirus 1, {{B}} parvovirus, goose parvovirus, duck reovirus, goose reovirus, duck hepatitis A virus, duck astrovirus, {{A}}, and goose hemorrhagic polyomavirus.\n"
     ]
    }
   ],
   "source": [
    "# choose a candidate for testing; can test different functions and regex rules here\n",
    "print(train_cands[140])\n",
    "sentence = train_cands[140].get_parent()  # get one exmaple sentence to test\n",
    "document = sentence.get_parent()\n",
    "print(sentence)\n",
    "print(\"Candidate LEFT tokens:   \\t\", list(get_left_tokens(train_cands[140],window=15)))\n",
    "print(\"Candidate RIGHT tokens:  \\t\", list(get_right_tokens(train_cands[140],window=15)))\n",
    "print(\"Candidate BETWEEN tokens:\\t\", get_text_between(train_cands[140]))\n",
    "print(\"Get tagged text:\\t\", get_tagged_text(train_cands[140]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Pattern based labeling functions, which look for certain keywords\n",
    "\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "# Positive LFs:\n",
    "\n",
    "detect = {'detect', 'detects', 'detected', 'detecting', 'detection', 'detectable'}\n",
    "detect_l = ['detect', 'detects', 'detected', 'detecting', 'detection', 'detectable']\n",
    "infect = {'infect', 'infects', 'infected', 'infecting', 'infection'}\n",
    "isolate = {'isolate', 'isolates', 'isolated', 'isolating', 'isolation'}\n",
    "other_verbs = {\n",
    "    'transmit(ted)?', 'found', 'find(ings)?', 'affect(s|ed|ing)?', 'confirm(s|ed|ing)?', 'relat(ed|es|e|ing|ion)?', 'recovered', 'identified', 'collected'\n",
    "}\n",
    "misc = {\n",
    "    'seropositive', 'seropositivity', 'positive', 'host(s)?', 'prevalen(ce|t)?', 'case(s)?', 'ELISA', 'titer', 'viremia', 'antibod(y|ies)?', 'antigen', 'exposure', 'PCR', 'polymerase chain reaction', 'RNA', 'DNA', 'nucleotide', 'sequence', 'evidence', 'common', 'success(fully)?', 'extract(ed)?', 'PFU', '(PFU)', 'plaque-forming unit', 'suscept', 'probably', 'probable', 'high(er)?'\n",
    "}\n",
    "\n",
    "causal = ['caus(es|ed|e|ing|ation)?', 'induc(es|ed|e|ing)?', 'associat(ed|ing|es|e|ion)?']\n",
    "\n",
    "positive = {'detect', 'detects', 'detected', 'detecting', 'detection', 'detectable', 'infect', 'infects', 'infected', 'infecting', 'infection', 'isolate', 'isolates', 'isolated', 'isolating', 'isolation'}\n",
    "positive_l = ['detect', 'detects', 'detected', 'detecting', 'detection', 'detectable', 'infect', 'infects', 'infected', 'infecting', 'infection', 'isolate', 'isolates', 'isolated', 'isolating', 'isolation']\n",
    "\n",
    "# negative words\n",
    "negative = {\n",
    "    'negative (antibodies)?', 'seronegative', 'seronegativity', 'negate', 'not', 'Not', '\\bno\\b', '\\bNo\\b', '(titer(s)?\\W+(?:\\w+\\W+){1,6}?less than)', 'titers against', 'none', 'resist', 'never'\n",
    "}\n",
    "negative_l = [\n",
    "    'negative (antibodies)?', 'seronegative', 'seronegativity', 'negate', 'not', 'Not', '\\bno\\b', '\\bNo\\b', '(titer(s)?\\W+(?:\\w+\\W+){1,6}?less than)', 'titers against', 'none', 'resist', 'never'\n",
    "]\n",
    "neg_rgx = r'|'.join(negative_l)\n",
    "\n",
    "# search nearby words for negatives, returns True if negative word found:\n",
    "def neg_nearby(c):  \n",
    "    if (len(negative.intersection(get_between_tokens(c))) > 0):\n",
    "        return True\n",
    "    elif (len(negative.intersection(get_left_tokens(c, window=15))) > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# words like detect \n",
    "def LF_detect(c):\n",
    "    if (len(detect.intersection(get_between_tokens(c))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(detect.intersection(get_left_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(detect.intersection(get_left_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(detect.intersection(get_right_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(detect.intersection(get_right_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def LF_infect(c):\n",
    "    if len(infect.intersection(get_between_tokens(c))) > 0  and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(infect.intersection(get_left_tokens(c[0], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(infect.intersection(get_left_tokens(c[1], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(infect.intersection(get_right_tokens(c[0], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(infect.intersection(get_right_tokens(c[1], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    # Words like 'isolated'\n",
    "def LF_isolate(c):\n",
    "    if len(isolate.intersection(get_between_tokens(c))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(isolate.intersection(get_left_tokens(c[0], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(isolate.intersection(get_left_tokens(c[1], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(isolate.intersection(get_right_tokens(c[0], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif len(isolate.intersection(get_right_tokens(c[1], window=20))) > 0 and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "        \n",
    "def LF_misc(c):\n",
    "    if (len(misc.intersection(get_between_tokens(c))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(misc.intersection(get_left_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(misc.intersection(get_left_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(misc.intersection(get_right_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(misc.intersection(get_right_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# terms like 'virus A caused disease in host B'\n",
    "def LF_v_cause_h(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,50}(not|no|negative).{0,20}' + ltp(causal) + '.{0,50}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "# if candidates are nearby and check for negative words\n",
    "def LF_v_h(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,200}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search(neg_rgx, get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "def LF_h_v(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{B}}.{0,250}{{A}}', get_tagged_text(c), re.I)\n",
    "        and not re.search(neg_rgx, get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "# positive verbs (detect, infect, isolate)\n",
    "def LF_positive(c):\n",
    "    if (len(positive.intersection(get_between_tokens(c))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(positive.intersection(get_left_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(positive.intersection(get_left_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(positive.intersection(get_right_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(positive.intersection(get_right_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def LF_positive2(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,100} ' + ltp(positive_l) + '.{0,100}{{B}}', get_tagged_text(c), re.I)\n",
    "        and not re.search('{{A}}.{0,100}(not|no|negative).{0,20}' + ltp(positive_l) + '.{0,100}{{B}}', get_tagged_text(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "def LF_other_verbs(c):\n",
    "    if (len(other_verbs.intersection(get_between_tokens(c))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(other_verbs.intersection(get_left_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(other_verbs.intersection(get_left_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(other_verbs.intersection(get_right_tokens(c[0], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    elif (len(other_verbs.intersection(get_right_tokens(c[1], window=20))) > 0) and not neg_nearby(c):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def LF_percents(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,100}' + '\\d+%|\\d+(.)?\\d+%' + '.{0,100}{{B}}', get_tagged_text(c), re.I) \n",
    "        and not re.search('(none|not|\\W+no\\W+|humidity)', get_text_between(c), re.I)\n",
    "    ) else 0\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "\n",
    "# Negative LFs:\n",
    "\n",
    "# Uncertain pairs\n",
    "uncertain = ['combin', 'possible', 'unlikely']\n",
    "\n",
    "def LF_uncertain(c):\n",
    "    return rule_regex_search_before_A(c, ltp(uncertain) + '.*', -1)\n",
    "\n",
    "# if candidate pair is too far apart, mark as negative\n",
    "def LF_far_v_h(c):\n",
    "    return rule_regex_search_btw_AB(c, '.{350,5000}', -1)\n",
    "\n",
    "def LF_far_h_v(c):\n",
    "    return rule_regex_search_btw_BA(c, '.{350,5000}', -1)\n",
    "\n",
    "def LF_neg_h(c):\n",
    "    return -1 if re.search(neg_rgx + '.{0,50}{{B}}', get_tagged_text(c), flags=re.I) else 0\n",
    "\n",
    "def LF_neg_assertions(c):\n",
    "    if (len(negative.intersection(get_between_tokens(c))) > 0): \n",
    "        return -1\n",
    "    elif (len(negative.intersection(get_left_tokens(c[0], window=10))) > 0):\n",
    "        return -1\n",
    "    elif (len(negative.intersection(get_left_tokens(c[1], window=20))) > 0):\n",
    "        return -1\n",
    "    elif (len(negative.intersection(get_right_tokens(c[0], window=20))) > 0):\n",
    "        return -1\n",
    "#    elif (len(negative.intersection(get_right_tokens(c[1], window=20))) > 0):\n",
    "#        return -1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distant Supervision LFs\n",
    "# Compare candidates with a database of known virus-host pairs (from Virus-Host Database)\n",
    "\n",
    "import bz2\n",
    "\n",
    "# Function to remove special characters from text\n",
    "def strip_special(s):\n",
    "    return ''.join(c for c in s if ord(c) < 128)\n",
    "\n",
    "# Read in known pairs and save as set of tuples\n",
    "with bz2.BZ2File('virushostdb.tar.bz2', 'rb') as f:\n",
    "    known_pairs = set(\n",
    "        tuple(strip_special(x.decode('utf-8')).strip().split('\\t')) for x in f.readlines()\n",
    "    )\n",
    "\n",
    "def LF_distant_supervision(c):\n",
    "    v, h = c.virus.get_span(), c.host.get_span()\n",
    "    return 1 if (v,h) in known_pairs else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all LFs\n",
    "LFs = [\n",
    "     LF_detect, LF_infect, LF_isolate, LF_positive, LF_positive2, LF_misc, LF_v_cause_h, LF_v_h, LF_h_v, LF_other_verbs, LF_uncertain, LF_far_v_h, LF_far_h_v, LF_neg_h, LF_distant_supervision, LF_neg_assertions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number labeled: 3642\n"
     ]
    }
   ],
   "source": [
    "# To label and view LFs for testing\n",
    "labeled = []\n",
    "for c in session.query(VirusHost).filter(VirusHost.split == 0).all():\n",
    "    for function in LFs:\n",
    "        if function(c) != 0:\n",
    "            if c not in labeled:\n",
    "                labeled.append(c)\n",
    "print(\"Number labeled:\", len(labeled))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### To view only a specific LF\n",
    "\n",
    "labeled2 = []\n",
    "for c in session.query(VirusHost).filter(VirusHost.split == 0).all():\n",
    "    if LF_far_v_h(c) != 0: # change this line to test a specified LF\n",
    "        if c not in labeled2:\n",
    "            labeled2.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SentenceNgramViewer(cids=[[[688, 2435, 2494], [2014, 2015], [412]], [[771, 1629], [45, 46], [213]], [[74, 1198…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "SentenceNgramViewer(labeled, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Applying Labeling Functions\n",
    "\n",
    "We run the LFs over all training candidates, producing a set of Labels (Virus and Host) and LabelKeys (the names of the LFs) in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the label annotator class\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Wall time: 29.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3795x16 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 7373 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1701)\n",
    "%time L_train = labeler.apply(split=0)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the returned matrix is a special subclass of the `scipy.sparse.csr_matrix` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VirusHost(Span(\"b'Zika'\", sentence=7285, chars=[15,18], words=[3,3]), Span(\"b'monkeys'\", sentence=7285, chars=[109,115], words=[18,18]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the candidate names and positions of any candidate in the set\n",
    "L_train.get_candidate(session, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelKey (LF_detect)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the LabelKey (the name of the LF used to identify the candidate)\n",
    "L_train.get_key(session, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing statistics about the resulting label matrix:\n",
    "\n",
    "* **Coverage** is the fraction of candidates that the labeling function emits a non-zero label for.\n",
    "* **Overlap** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for.\n",
    "* **Conflict** is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a *conflicting* non-zero label for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_detect</th>\n",
       "      <td>0</td>\n",
       "      <td>0.062978</td>\n",
       "      <td>0.062978</td>\n",
       "      <td>0.015547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_infect</th>\n",
       "      <td>1</td>\n",
       "      <td>0.054809</td>\n",
       "      <td>0.054809</td>\n",
       "      <td>0.015020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_isolate</th>\n",
       "      <td>2</td>\n",
       "      <td>0.075362</td>\n",
       "      <td>0.075362</td>\n",
       "      <td>0.021607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive</th>\n",
       "      <td>3</td>\n",
       "      <td>0.172069</td>\n",
       "      <td>0.172069</td>\n",
       "      <td>0.043215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.044532</td>\n",
       "      <td>0.044532</td>\n",
       "      <td>0.008432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_misc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.253228</td>\n",
       "      <td>0.239526</td>\n",
       "      <td>0.143610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_cause_h</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.005797</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_h</th>\n",
       "      <td>7</td>\n",
       "      <td>0.259552</td>\n",
       "      <td>0.134651</td>\n",
       "      <td>0.003162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_h_v</th>\n",
       "      <td>8</td>\n",
       "      <td>0.187615</td>\n",
       "      <td>0.066930</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_other_verbs</th>\n",
       "      <td>9</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.058235</td>\n",
       "      <td>0.017128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.003162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_v_h</th>\n",
       "      <td>11</td>\n",
       "      <td>0.219763</td>\n",
       "      <td>0.185244</td>\n",
       "      <td>0.095916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_h_v</th>\n",
       "      <td>12</td>\n",
       "      <td>0.091436</td>\n",
       "      <td>0.072200</td>\n",
       "      <td>0.032148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_h</th>\n",
       "      <td>13</td>\n",
       "      <td>0.381555</td>\n",
       "      <td>0.293281</td>\n",
       "      <td>0.146509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_distant_supervision</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_assertions</th>\n",
       "      <td>15</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.069565</td>\n",
       "      <td>0.010804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j  Coverage  Overlaps  Conflicts\n",
       "LF_detect                0  0.062978  0.062978   0.015547\n",
       "LF_infect                1  0.054809  0.054809   0.015020\n",
       "LF_isolate               2  0.075362  0.075362   0.021607\n",
       "LF_positive              3  0.172069  0.172069   0.043215\n",
       "LF_positive2             4  0.044532  0.044532   0.008432\n",
       "LF_misc                  5  0.253228  0.239526   0.143610\n",
       "LF_v_cause_h             6  0.005797  0.005797   0.001054\n",
       "LF_v_h                   7  0.259552  0.134651   0.003162\n",
       "LF_h_v                   8  0.187615  0.066930   0.000000\n",
       "LF_other_verbs           9  0.060606  0.058235   0.017128\n",
       "LF_uncertain            10  0.003426  0.003162   0.003162\n",
       "LF_far_v_h              11  0.219763  0.185244   0.095916\n",
       "LF_far_h_v              12  0.091436  0.072200   0.032148\n",
       "LF_neg_h                13  0.381555  0.293281   0.146509\n",
       "LF_distant_supervision  14  0.000527  0.000527   0.000000\n",
       "LF_neg_assertions       15  0.069565  0.069565   0.010804"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Checking Against Gold Labels (Hand Labeled Set)\n",
    "- Run the labeler on the development set\n",
    "- Load in some external labels:\n",
    "\n",
    "### Load Gold Labels\n",
    "Gold labels are a _small_ set of examples (here, a subset of our training set) which we label by hand and use to help us develop and refine labeling functions. Unlike the _test set_, which we do not look at and use for final evaluation, we can inspect the development set while writing labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "from util_virushost import load_external_labels\n",
    "\n",
    "%time missed = load_external_labels(session, VirusHost, annotator_name = 'gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150x1 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 118 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name = \"gold\", split=1)\n",
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Wall time: 1.89 s\n"
     ]
    }
   ],
   "source": [
    "%time L_dev = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erica\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\snorkel\\annotations.py:137: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ac = (tp+tn) / (tp+tn+fp+fn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_detect</th>\n",
       "      <td>0</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_infect</th>\n",
       "      <td>1</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_isolate</th>\n",
       "      <td>2</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive</th>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_misc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.273333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_cause_h</th>\n",
       "      <td>6</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_h</th>\n",
       "      <td>7</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_h_v</th>\n",
       "      <td>8</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_other_verbs</th>\n",
       "      <td>9</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_v_h</th>\n",
       "      <td>11</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_h_v</th>\n",
       "      <td>12</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_h</th>\n",
       "      <td>13</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_distant_supervision</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_assertions</th>\n",
       "      <td>15</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j  Coverage  Overlaps  Conflicts  TP  FP  FN  TN  \\\n",
       "LF_detect                0  0.093333  0.093333   0.000000   8   0   0   0   \n",
       "LF_infect                1  0.066667  0.066667   0.006667  10   0   0   0   \n",
       "LF_isolate               2  0.006667  0.006667   0.000000   0   0   0   0   \n",
       "LF_positive              3  0.166667  0.166667   0.006667  18   0   0   0   \n",
       "LF_positive2             4  0.060000  0.060000   0.000000   5   0   0   0   \n",
       "LF_misc                  5  0.273333  0.273333   0.100000  29   1   0   0   \n",
       "LF_v_cause_h             6  0.013333  0.013333   0.000000   2   0   0   0   \n",
       "LF_v_h                   7  0.413333  0.166667   0.000000  45   3   0   0   \n",
       "LF_h_v                   8  0.320000  0.200000   0.000000  43   0   0   0   \n",
       "LF_other_verbs           9  0.140000  0.140000   0.013333  12   1   0   0   \n",
       "LF_uncertain            10  0.000000  0.000000   0.000000   0   0   0   0   \n",
       "LF_far_v_h              11  0.006667  0.006667   0.006667   0   0   1   0   \n",
       "LF_far_h_v              12  0.026667  0.013333   0.013333   0   0   3   0   \n",
       "LF_neg_h                13  0.200000  0.173333   0.100000   0   0  15   3   \n",
       "LF_distant_supervision  14  0.000000  0.000000   0.000000   0   0   0   0   \n",
       "LF_neg_assertions       15  0.093333  0.093333   0.020000   0   0   5   0   \n",
       "\n",
       "                        Empirical Acc.  \n",
       "LF_detect                     1.000000  \n",
       "LF_infect                     1.000000  \n",
       "LF_isolate                         NaN  \n",
       "LF_positive                   1.000000  \n",
       "LF_positive2                  1.000000  \n",
       "LF_misc                       0.966667  \n",
       "LF_v_cause_h                  1.000000  \n",
       "LF_v_h                        0.937500  \n",
       "LF_h_v                        1.000000  \n",
       "LF_other_verbs                0.923077  \n",
       "LF_uncertain                       NaN  \n",
       "LF_far_v_h                    0.000000  \n",
       "LF_far_h_v                    0.000000  \n",
       "LF_neg_h                      0.166667  \n",
       "LF_distant_supervision             NaN  \n",
       "LF_neg_assertions             0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Matrix Empirical Accuracies\n",
    "\n",
    "L_dev.lf_stats(session, labels=L_gold_dev.toarray().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "from util_virushost import load_external_labels\n",
    "\n",
    "%time missed = load_external_labels(session, VirusHost, annotator_name = 'gold', split = 2)\n",
    "L_gold_test = load_gold_labels(session, annotator_name = \"gold\", split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Wall time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "%time L_test = labeler.apply_existing(split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_detect</th>\n",
       "      <td>0</td>\n",
       "      <td>0.072829</td>\n",
       "      <td>0.072829</td>\n",
       "      <td>0.025210</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_infect</th>\n",
       "      <td>1</td>\n",
       "      <td>0.064426</td>\n",
       "      <td>0.064426</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_isolate</th>\n",
       "      <td>2</td>\n",
       "      <td>0.056022</td>\n",
       "      <td>0.056022</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive</th>\n",
       "      <td>3</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.030812</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_misc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.495798</td>\n",
       "      <td>0.453782</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_cause_h</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_h</th>\n",
       "      <td>7</td>\n",
       "      <td>0.243697</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_h_v</th>\n",
       "      <td>8</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>0.089636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_other_verbs</th>\n",
       "      <td>9</td>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.106443</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>10</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_v_h</th>\n",
       "      <td>11</td>\n",
       "      <td>0.288515</td>\n",
       "      <td>0.288515</td>\n",
       "      <td>0.288515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_h_v</th>\n",
       "      <td>12</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_h</th>\n",
       "      <td>13</td>\n",
       "      <td>0.226891</td>\n",
       "      <td>0.140056</td>\n",
       "      <td>0.072829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_distant_supervision</th>\n",
       "      <td>14</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_assertions</th>\n",
       "      <td>15</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.011204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j  Coverage  Overlaps  Conflicts  TP  FP  FN  TN  \\\n",
       "LF_detect                0  0.072829  0.072829   0.025210   7   0   0   0   \n",
       "LF_infect                1  0.064426  0.064426   0.002801   9   0   0   0   \n",
       "LF_isolate               2  0.056022  0.056022   0.002801   8   0   0   0   \n",
       "LF_positive              3  0.176471  0.176471   0.030812  24   0   0   0   \n",
       "LF_positive2             4  0.047619  0.047619   0.000000   6   0   0   0   \n",
       "LF_misc                  5  0.495798  0.453782   0.313725   6   0   0   0   \n",
       "LF_v_cause_h             6  0.005602  0.005602   0.002801   0   0   0   0   \n",
       "LF_v_h                   7  0.243697  0.176471   0.000000  23   0   0   0   \n",
       "LF_h_v                   8  0.184874  0.089636   0.000000  12   0   0   0   \n",
       "LF_other_verbs           9  0.109244  0.106443   0.067227   2   1   0   0   \n",
       "LF_uncertain            10  0.002801  0.002801   0.002801   0   0   0   0   \n",
       "LF_far_v_h              11  0.288515  0.288515   0.288515   0   0   1   0   \n",
       "LF_far_h_v              12  0.005602  0.005602   0.002801   0   0   0   0   \n",
       "LF_neg_h                13  0.226891  0.140056   0.072829   0   0   0   1   \n",
       "LF_distant_supervision  14  0.002801  0.002801   0.000000   0   0   0   0   \n",
       "LF_neg_assertions       15  0.075630  0.075630   0.011204   0   0   0   0   \n",
       "\n",
       "                        Empirical Acc.  \n",
       "LF_detect                     1.000000  \n",
       "LF_infect                     1.000000  \n",
       "LF_isolate                    1.000000  \n",
       "LF_positive                   1.000000  \n",
       "LF_positive2                  1.000000  \n",
       "LF_misc                       1.000000  \n",
       "LF_v_cause_h                       NaN  \n",
       "LF_v_h                        1.000000  \n",
       "LF_h_v                        1.000000  \n",
       "LF_other_verbs                0.666667  \n",
       "LF_uncertain                       NaN  \n",
       "LF_far_v_h                    0.000000  \n",
       "LF_far_h_v                         NaN  \n",
       "LF_neg_h                      1.000000  \n",
       "LF_distant_supervision             NaN  \n",
       "LF_neg_assertions                  NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_test.lf_stats(session, labels=L_gold_test.toarray().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Labeling Functions used:  16\n"
     ]
    }
   ],
   "source": [
    "print('Number of Labeling Functions used: ', len(LFs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterating on Labeling Function Design:\n",
    "When writing labeling functions, you will want to iterate on the process outlined above several times. You should focus on tuning individual LFs, based on emprical accuracy metrics, and adding new LFs to improve coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### See Notebook Part 3 for Generative Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel!)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
