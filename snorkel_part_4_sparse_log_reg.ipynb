{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virus-Host Species Relation Extraction\n",
    "## Notebook 4 -  End Model (Sparse Logistic Regression)\n",
    "### UC Davis Epicenter for Disease Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "import pandas as pd\n",
    "session = SnorkelSession()\n",
    "# Connect to the database backend and initalize a Snorkel session\n",
    "\n",
    "#from lib.init import *\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "VirusHost = candidate_subclass('VirusHost', ['virus', 'host'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "\n",
    "train_cands = session.query(VirusHost).filter(VirusHost.split == 0).order_by(VirusHost.id).all()\n",
    "dev_cands   = session.query(VirusHost).filter(VirusHost.split == 1).order_by(VirusHost.id).all()\n",
    "test_cands  = session.query(VirusHost).filter(VirusHost.split == 2).order_by(VirusHost.id).all()\n",
    "\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, load_as_array=True, zero_one=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<539x1 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 110 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util_virushost import load_external_labels\n",
    "\n",
    "missed = load_external_labels(session, VirusHost, annotator_name = 'gold', split=2)\n",
    "\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2, zero_one=True)\n",
    "L_gold_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "Instead of using a deep learning approach to start, let's look at a standard sparse logistic regression model. First, we need to extract out features. This can take a while, but we only have to do it once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import hybrid_span_mention_ftrs\n",
    "from snorkel.annotations import FeatureAnnotator\n",
    "\n",
    "featurizer = FeatureAnnotator(f=hybrid_span_mention_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 3805/3805 [03:16<00:00, 19.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 19s\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 428/428 [00:27<00:00, 15.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.5 s\n",
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 539/539 [01:27<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 29s\n",
      "(3805, 54775)\n",
      "(428, 54775)\n",
      "(539, 54775)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev   = featurizer.load_matrix(session, split=1)\n",
    "F_test  = featurizer.load_matrix(session, split=2)\n",
    "\n",
    "if F_train.size == 0:    \n",
    "    %time F_train = featurizer.apply(split=0, parallelism=1)\n",
    "if F_dev.size == 0:     \n",
    "    %time F_dev  = featurizer.apply_existing(split=1, parallelism=1)\n",
    "if F_test.size == 0:\n",
    "    %time F_test = featurizer.apply_existing(split=2, parallelism=1)\n",
    "\n",
    "print(F_train.shape)\n",
    "print(F_dev.shape)\n",
    "print(F_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Discriminitive Model Parameter Space (seed=1234):\n",
      "0 (128, 0.0001, 0.01, 0.01, 0.0)\n",
      "1 (128, 0.0001, 0.01, 0.01, 0.5)\n",
      "2 (64, 0.001, 0.01, 0.01, 0.0)\n",
      "3 (128, 0.001, 1e-06, 1e-06, 0.5)\n",
      "4 (64, 0.001, 1e-06, 1e-06, 0.5)\n",
      "============================================================\n",
      "[1] Testing batch_size = 64, lr = 1.00e-04, l1_penalty = 1.00e-06, l2_penalty = 1.00e-04, rebalance = 0.00e+00\n",
      "============================================================\n",
      "WARNING:tensorflow:From C:\\Users\\ericaxia3\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ericaxia3\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericaxia3\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3747  #epochs=30  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (3.74s)\tAverage loss=0.766726\tDev F1=31.46\n",
      "[SparseLogisticRegression] Epoch 10 (25.09s)\tAverage loss=0.634736\tDev F1=33.99\n",
      "[SparseLogisticRegression] Epoch 20 (46.08s)\tAverage loss=0.611430\tDev F1=34.73\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 29 (65.78s)\tAverage loss=0.600980\tDev F1=35.10\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (66.32s)\n",
      "WARNING:tensorflow:From C:\\Users\\ericaxia3\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\SparseLogisticRegression\\SparseLogisticRegression-29\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1 Score: 0.35097493036211697\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_0>\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_best>\n",
      "============================================================\n",
      "[2] Testing batch_size = 64, lr = 1.00e-03, l1_penalty = 1.00e-04, l2_penalty = 1.00e-02, rebalance = 5.00e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3518  #epochs=30  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (2.21s)\tAverage loss=2.933018\tDev F1=34.04\n",
      "[SparseLogisticRegression] Epoch 10 (21.82s)\tAverage loss=0.599489\tDev F1=34.18\n",
      "[SparseLogisticRegression] Epoch 20 (41.44s)\tAverage loss=0.595219\tDev F1=33.66\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 29 (59.98s)\tAverage loss=0.595783\tDev F1=37.78\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (60.29s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\SparseLogisticRegression\\SparseLogisticRegression-29\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1 Score: 0.37777777777777777\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_1>\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_best>\n",
      "============================================================\n",
      "[3] Testing batch_size = 128, lr = 1.00e-02, l1_penalty = 1.00e-06, l2_penalty = 1.00e-04, rebalance = 0.00e+00\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3747  #epochs=30  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (1.61s)\tAverage loss=0.732157\tDev F1=30.73\n",
      "[SparseLogisticRegression] Epoch 10 (14.98s)\tAverage loss=0.687068\tDev F1=31.22\n",
      "[SparseLogisticRegression] Epoch 20 (28.30s)\tAverage loss=0.658599\tDev F1=33.42\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 29 (40.48s)\tAverage loss=0.667796\tDev F1=33.02\n",
      "[SparseLogisticRegression] Training done (40.51s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\SparseLogisticRegression\\SparseLogisticRegression-20\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1 Score: 0.3341772151898735\n",
      "============================================================\n",
      "[4] Testing batch_size = 64, lr = 1.00e-02, l1_penalty = 1.00e-02, l2_penalty = 1.00e-02, rebalance = 0.00e+00\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3747  #epochs=30  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (2.29s)\tAverage loss=8.293977\tDev F1=45.85\n",
      "[SparseLogisticRegression] Epoch 10 (23.51s)\tAverage loss=1.289681\tDev F1=40.23\n",
      "[SparseLogisticRegression] Epoch 20 (45.00s)\tAverage loss=1.288492\tDev F1=41.46\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 29 (64.53s)\tAverage loss=1.287751\tDev F1=46.67\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (64.86s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\SparseLogisticRegression\\SparseLogisticRegression-29\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1 Score: 0.46666666666666673\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_3>\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_best>\n",
      "============================================================\n",
      "[5] Testing batch_size = 64, lr = 1.00e-02, l1_penalty = 1.00e-06, l2_penalty = 1.00e-06, rebalance = 5.00e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3518  #epochs=30  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (2.36s)\tAverage loss=0.718374\tDev F1=30.73\n",
      "[SparseLogisticRegression] Epoch 10 (22.03s)\tAverage loss=0.747575\tDev F1=36.58\n",
      "[SparseLogisticRegression] Epoch 20 (41.59s)\tAverage loss=0.756536\tDev F1=34.94\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 29 (59.66s)\tAverage loss=0.743174\tDev F1=39.05\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (60.06s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\SparseLogisticRegression\\SparseLogisticRegression-29\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1 Score: 0.39053254437869817\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\grid_search\\SparseLogisticRegression_3\\SparseLogisticRegression_3-0\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression_3>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>l1_penalty</th>\n",
       "      <th>l2_penalty</th>\n",
       "      <th>rebalance</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.253846</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.390533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.241135</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.224199</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.350975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208202</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.334177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size      lr  l1_penalty  l2_penalty  rebalance     Prec.      Rec.  \\\n",
       "3          64  0.0100    0.010000    0.010000        0.0  0.328125  0.807692   \n",
       "4          64  0.0100    0.000001    0.000001        0.5  0.253846  0.846154   \n",
       "1          64  0.0010    0.000100    0.010000        0.5  0.241135  0.871795   \n",
       "0          64  0.0001    0.000001    0.000100        0.0  0.224199  0.807692   \n",
       "2         128  0.0100    0.000001    0.000100        0.0  0.208202  0.846154   \n",
       "\n",
       "        F-1  \n",
       "3  0.466667  \n",
       "4  0.390533  \n",
       "1  0.377778  \n",
       "0  0.350975  \n",
       "2  0.334177  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.learning import RandomSearch\n",
    "from snorkel.learning.tensorflow import SparseLogisticRegression\n",
    "\n",
    "seed = 1234\n",
    "num_model_search = 5\n",
    "\n",
    "# search over this parameter grid\n",
    "param_grid = {}\n",
    "param_grid['batch_size'] = [64, 128]\n",
    "param_grid['lr']         = [1e-4, 1e-3, 1e-2]\n",
    "param_grid['l1_penalty'] = [1e-6, 1e-4, 1e-2]\n",
    "param_grid['l2_penalty'] = [1e-6, 1e-4, 1e-2]\n",
    "param_grid['rebalance']  = [0.0, 0.5]\n",
    "\n",
    "model_class_params = {\n",
    "    'n_threads':1\n",
    "}\n",
    "\n",
    "model_hyperparams = {\n",
    "    'n_epochs': 30,\n",
    "    'print_freq': 10,\n",
    "    'dev_ckpt_delay': 0.5,\n",
    "    'X_dev': F_dev,\n",
    "    'Y_dev': L_gold_dev\n",
    "}\n",
    "\n",
    "searcher = RandomSearch(SparseLogisticRegression, param_grid, F_train, train_marginals,\n",
    "                        n=num_model_search, seed=seed,\n",
    "                        model_class_params=model_class_params,\n",
    "                        model_hyperparams=model_hyperparams)\n",
    "\n",
    "print(\"Discriminitive Model Parameter Space (seed={}):\".format(seed))\n",
    "for i, params in enumerate(searcher.search_space()):\n",
    "    print(\"{} {}\".format(i, params))\n",
    "\n",
    "disc_model, run_stats = searcher.fit(X_valid=F_dev, Y_valid=L_gold_dev, n_threads=1)\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54775\n",
      "[-0.23769023, 'BETWEEN_SEQ_POS_TAGS[NNP NNP NNP]']\n",
      "[-0.15579031, 'WIN_RIGHT_SEQ_POS_TAGS[NNP NNP]']\n",
      "[-0.14817533, 'BETWEEN_SEQ_POS_TAGS[NNP NNP]']\n",
      "[-0.14448415, 'BETWEEN_LEMMAS[40]']\n",
      "[-0.1382108, 'BETWEEN_SEQ_POS_TAGS[CD NNP]']\n",
      "[-0.107101396, 'BETWEEN_SEQ_POS_TAGS[NNP NNP CD]']\n",
      "[-0.09070521, 'BETWEEN_SEQ_POS_TAGS[CD NNP NNP]']\n",
      "[-0.086096965, 'BETWEEN_POS_TAGS[CD]']\n",
      "[-0.085858606, 'BETWEEN_LEMMAS[wnv]']\n",
      "[-0.047634784, 'BETWEEN_SEQ_POS_TAGS[NNP NNP ,]']\n",
      "[-0.03262218, 'BETWEEN_POS_TAGS[RB]']\n",
      "[-0.022592578, 'WIN_LEFT_POS_TAGS[NNP]']\n",
      "[-0.022129225, 'BETWEEN_SEQ_POS_TAGS[NN -LRB-]']\n",
      "[-0.021860994, 'BETWEEN_SEQ_POS_TAGS[VBN NN -LRB-]']\n",
      "[-0.019906584, 'BETWEEN_SEQ_POS_TAGS[JJ NN]']\n",
      "[-0.019017868, 'BETWEEN_LEMMAS[4]']\n",
      "[-0.017826296, 'BETWEEN_POS_TAGS[$]']\n",
      "[-0.01670544, 'WIN_LEFT_SEQ_POS_TAGS[NNP NNP]']\n",
      "[-0.016157726, 'BETWEEN_SEQ_POS_TAGS[NNP XX CD]']\n",
      "[-0.01613489, 'BETWEEN_LEMMAS[1]']\n",
      "[-0.015286283, 'BETWEEN_LEMMAS[13]']\n",
      "[-0.015048918, 'BETWEEN_LEMMAS[usuv]']\n",
      "[-0.014508486, 'BETWEEN_SEQ_POS_TAGS[-LRB- NNP]']\n",
      "[-0.013920519, 'BETWEEN_SEQ_LEMMAS[40 160]']\n",
      "[-0.012910673, 'WIN_RIGHT_SEQ_POS_TAGS[NNP NNP NNP]']\n",
      "[-0.0128365345, 'BETWEEN_SEQ_POS_TAGS[NNP NNP NN]']\n",
      "[-0.012729143, 'WIN_RIGHT_SEQ_POS_TAGS[-LRB- NNP]']\n",
      "[-0.012414569, 'BETWEEN_POS_TAGS[VBN]']\n",
      "[-0.012230158, 'WIN_RIGHT_POS_TAGS[NNP]']\n",
      "[-0.0117272865, 'BETWEEN_SEQ_POS_TAGS[NNP NN -LRB-]']\n",
      "[-0.011700374, 'BETWEEN_LEMMAS[5]']\n",
      "[-0.011386381, 'BETWEEN_SEQ_POS_TAGS[NN NN]']\n",
      "[-0.011348178, 'BETWEEN_SEQ_POS_TAGS[RB VBN]']\n",
      "[-0.010898264, 'BETWEEN_SEQ_POS_TAGS[HYPH VBN]']\n",
      "[-0.010794172, 'BETWEEN_SEQ_POS_TAGS[NN -LRB- NNP]']\n",
      "[-0.010600912, 'WIN_RIGHT_SEQ_POS_TAGS[-LRB- NNP NNP]']\n",
      "[-0.010587226, 'BETWEEN_LEMMAS[320]']\n",
      "[-0.010499253, 'BETWEEN_SEQ_POS_TAGS[NNP -LRB-]']\n",
      "[-0.010398327, 'WIN_RIGHT_POS_TAGS[CC]']\n",
      "[-0.010354681, 'BETWEEN_SEQ_LEMMAS[< 40]']\n",
      "[-0.009823023, 'BETWEEN_SEQ_POS_TAGS[$ CD NNP]']\n",
      "[-0.009684755, 'BETWEEN_SEQ_POS_TAGS[NNP CD]']\n",
      "[-0.009535499, 'WIN_LEFT_POS_TAGS[NNS]']\n",
      "[-0.00926614, 'BETWEEN_SEQ_LEMMAS[neg chicken 2]']\n",
      "[-0.009026887, 'BETWEEN_SEQ_LEMMAS[neg ne ne]']\n",
      "[-0.008984458, 'BETWEEN_SEQ_LEMMAS[40 320]']\n",
      "[-0.008798361, 'BETWEEN_SEQ_POS_TAGS[NNP ,]']\n",
      "[-0.008795672, 'BETWEEN_SEQ_LEMMAS[40 320 wnv]']\n",
      "[-0.008755228, 'BETWEEN_SEQ_POS_TAGS[VBN NN]']\n",
      "[-0.008743151, 'BETWEEN_SEQ_POS_TAGS[HYPH VBN NN]']\n",
      "--------------------\n",
      "[0.004857155, 'WIN_LEFT_SEQ_POS_TAGS[NNP HYPH]']\n",
      "[0.00485754, 'WIN_LEFT_SEQ_LEMMAS[, coryphistera]']\n",
      "[0.004862792, 'BETWEEN_SEQ_LEMMAS[also support]']\n",
      "[0.004864932, 'BETWEEN_SEQ_POS_TAGS[IN NNS CC]']\n",
      "[0.0048881792, 'BETWEEN_SEQ_LEMMAS[motacilla flava]']\n",
      "[0.004907534, 'BETWEEN_SEQ_POS_TAGS[HYPH NNP]']\n",
      "[0.004907607, 'BETWEEN_LEMMAS[237]']\n",
      "[0.0049103973, 'BETWEEN_SEQ_LEMMAS[stork test have]']\n",
      "[0.004940016, 'BETWEEN_SEQ_POS_TAGS[CC IN NNS]']\n",
      "[0.0049401564, 'BETWEEN_SEQ_LEMMAS[test have]']\n",
      "[0.00494222, 'WIN_LEFT_SEQ_LEMMAS[stork test]']\n",
      "[0.0049598627, 'BETWEEN_LEMMAS[stage]']\n",
      "[0.004976119, 'BETWEEN_SEQ_POS_TAGS[VBG NNS VBD]']\n",
      "[0.0049937475, 'WIN_LEFT_LEMMAS[nairovirus]']\n",
      "[0.0049943435, 'BETWEEN_SEQ_LEMMAS[disease hosts mortality]']\n",
      "[0.0049985982, 'BETWEEN_SEQ_LEMMAS[disease hosts]']\n",
      "[0.0049985982, 'BETWEEN_SEQ_LEMMAS[rate russian spring]']\n",
      "[0.0050114174, 'BETWEEN_SEQ_LEMMAS[virus in swine]']\n",
      "[0.0050500548, 'WIN_LEFT_SEQ_POS_TAGS[TO VB JJ]']\n",
      "[0.0050581465, 'BETWEEN_SEQ_LEMMAS[dem- onstrating]']\n",
      "[0.005058147, 'BETWEEN_SEQ_LEMMAS[onstrating of]']\n",
      "[0.00507386, 'WIN_LEFT_SEQ_LEMMAS[to be]']\n",
      "[0.0050772573, 'BETWEEN_SEQ_LEMMAS[montenegro , italy]']\n",
      "[0.0050838576, 'BETWEEN_SEQ_POS_TAGS[NN IN JJ]']\n",
      "[0.005100335, 'BETWEEN_SEQ_LEMMAS[bullfinch ( pyrrhula]']\n",
      "[0.0051109744, 'BETWEEN_SEQ_LEMMAS[of isolation]']\n",
      "[0.0051184837, 'BETWEEN_SEQ_LEMMAS[fatal disease]']\n",
      "[0.0051656673, 'BETWEEN_SEQ_LEMMAS[nt . )]']\n",
      "[0.005168471, 'BETWEEN_SEQ_LEMMAS[and compare to]']\n",
      "[0.005216359, 'BETWEEN_SEQ_LEMMAS[usuv positive %]']\n",
      "[0.0052355784, 'BETWEEN_SEQ_POS_TAGS[-LRB- UH -RRB-]']\n",
      "[0.0052457466, 'WIN_RIGHT_SEQ_LEMMAS[serum ( 1]']\n",
      "[0.005314672, 'BETWEEN_SEQ_LEMMAS[parasitol res (]']\n",
      "[0.005456362, 'BETWEEN_SEQ_LEMMAS[urban birds]']\n",
      "[0.005461284, 'BETWEEN_LEMMAS[tal]']\n",
      "[0.0054678563, 'BETWEEN_SEQ_LEMMAS[in to- tal]']\n",
      "[0.005541132, 'WIN_RIGHT_SEQ_POS_TAGS[RB JJ]']\n",
      "[0.0056281574, 'BETWEEN_SEQ_LEMMAS[vee- tc83� vee-]']\n",
      "[0.0056289225, 'BETWEEN_SEQ_LEMMAS[noveboracensis)d < 40]']\n",
      "[0.0057711494, 'BETWEEN_SEQ_POS_TAGS[CC NN NNS]']\n",
      "[0.0059114387, 'BETWEEN_SEQ_POS_TAGS[NNP IN]']\n",
      "[0.0063800714, 'BETWEEN_SEQ_LEMMAS[by circulate]']\n",
      "[0.0063800714, 'BETWEEN_SEQ_LEMMAS[guzman1 ,]']\n",
      "[0.0063800733, 'BETWEEN_SEQ_LEMMAS[marín although]']\n",
      "[0.00849925, 'WIN_RIGHT_SEQ_POS_TAGS[CD CD]']\n",
      "[0.008669445, 'WIN_LEFT_SEQ_POS_TAGS[NN IN]']\n",
      "[0.009092873, 'BETWEEN_SEQ_POS_TAGS[IN NNP]']\n",
      "[0.013356358, 'WIN_LEFT_LEMMAS[of]']\n",
      "[0.13140471, 'BETWEEN_POS_TAGS[IN]']\n"
     ]
    }
   ],
   "source": [
    "# Extracting features allows us to inspect and interperet our learned weights\n",
    "from scoring import *\n",
    "print_top_k_features(session, disc_model, F_train, top_k=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.320, Recall: 0.642, F1 Score: 0.427\n"
     ]
    }
   ],
   "source": [
    "# Scores on the test set\n",
    "p, r, f1 = disc_model.score(F_test, L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel!)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
