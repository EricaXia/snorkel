{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virus-Host Species Relation Extraction\n",
    "## Notebook 4\n",
    "### UC Davis Epicenter for Disease Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "import pandas as pd\n",
    "session = SnorkelSession()\n",
    "# Connect to the database backend and initalize a Snorkel session\n",
    "\n",
    "#from lib.init import *\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "VirusHost = candidate_subclass('VirusHost', ['virus', 'host'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "\n",
    "train_cands = session.query(VirusHost).filter(VirusHost.split == 0).order_by(VirusHost.id).all()\n",
    "dev_cands   = session.query(VirusHost).filter(VirusHost.split == 1).order_by(VirusHost.id).all()\n",
    "test_cands  = session.query(VirusHost).filter(VirusHost.split == 2).order_by(VirusHost.id).all()\n",
    "\n",
    "L_gold_dev  = load_gold_labels(session, annotator_name='gold', split=1, load_as_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 37\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<362x1 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 37 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util_virushost import load_external_labels\n",
    "\n",
    "missed = load_external_labels(session, VirusHost, annotator_name = 'gold', split = 2)\n",
    "\n",
    "L_gold_test = load_gold_labels(session, annotator_name = 'gold', split = 2)\n",
    "\n",
    "L_gold_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    "Instead of using a deep learning approach to start, let's look at a standard sparse logistic regression model. First, we need to extract out features. This can take a while, but we only have to do it once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features import hybrid_span_mention_ftrs\n",
    "from snorkel.annotations import FeatureAnnotator\n",
    "\n",
    "featurizer = FeatureAnnotator(f=hybrid_span_mention_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Wall time: 5min 46s\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Wall time: 14.3 s\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "Wall time: 50.9 s\n",
      "(3631, 52127)\n",
      "(175, 52127)\n",
      "(362, 52127)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev   = featurizer.load_matrix(session, split=1)\n",
    "F_test  = featurizer.load_matrix(session, split=2)\n",
    "\n",
    "if F_train.size == 0:    \n",
    "    %time F_train = featurizer.apply(split=0, parallelism=1)\n",
    "if F_dev.size == 0:     \n",
    "    %time F_dev  = featurizer.apply_existing(split=1, parallelism=1)\n",
    "if F_test.size == 0:\n",
    "    %time F_test = featurizer.apply_existing(split=2, parallelism=1)\n",
    "\n",
    "print(F_train.shape)\n",
    "print(F_dev.shape)\n",
    "print(F_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Grid Search for Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "Discriminitive Model Parameter Space (seed=1234):\n",
      "0 (128, 0.0001, 0.01, 0.01, 0.0)\n",
      "1 (128, 0.0001, 0.01, 0.01, 0.5)\n",
      "2 (64, 0.001, 0.01, 0.01, 0.0)\n",
      "3 (128, 0.001, 1e-06, 1e-06, 0.5)\n",
      "4 (64, 0.001, 1e-06, 1e-06, 0.5)\n",
      "============================================================\n",
      "[1] Testing batch_size = 64, lr = 1.00e-04, l1_penalty = 1.00e-06, l2_penalty = 1.00e-04, rebalance = 0.00e+00\n",
      "============================================================\n",
      "WARNING:tensorflow:From C:\\Users\\erica\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\erica\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erica\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3585  #epochs=30  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (3.80s)\tAverage loss=0.927738\tDev F1=66.05\n",
      "[SparseLogisticRegression] Epoch 10 (32.43s)\tAverage loss=0.644058\tDev F1=67.29\n",
      "[SparseLogisticRegression] Epoch 20 (62.57s)\tAverage loss=0.614977\tDev F1=67.58\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 29 (88.43s)\tAverage loss=0.598269\tDev F1=68.47\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (88.75s)\n",
      "WARNING:tensorflow:From C:\\Users\\erica\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\SparseLogisticRegression\\SparseLogisticRegression-29\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1 Score: 0.6846846846846847\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_0>\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_best>\n",
      "============================================================\n",
      "[2] Testing batch_size = 64, lr = 1.00e-03, l1_penalty = 1.00e-04, l2_penalty = 1.00e-02, rebalance = 5.00e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3288  #epochs=30  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (3.04s)\tAverage loss=2.923812\tDev F1=70.48\n",
      "[SparseLogisticRegression] Epoch 10 (29.04s)\tAverage loss=0.603202\tDev F1=77.97\n",
      "[SparseLogisticRegression] Epoch 20 (55.43s)\tAverage loss=0.592766\tDev F1=79.51\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 29 (79.59s)\tAverage loss=0.592592\tDev F1=79.84\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (79.94s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\SparseLogisticRegression\\SparseLogisticRegression-29\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1 Score: 0.7983539094650205\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_1>\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_best>\n",
      "============================================================\n",
      "[3] Testing batch_size = 128, lr = 1.00e-02, l1_penalty = 1.00e-06, l2_penalty = 1.00e-04, rebalance = 0.00e+00\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3585  #epochs=30  batch size=128\n",
      "[SparseLogisticRegression] Epoch 0 (2.65s)\tAverage loss=0.736028\tDev F1=66.96\n",
      "[SparseLogisticRegression] Epoch 10 (22.49s)\tAverage loss=0.678219\tDev F1=69.31\n",
      "[SparseLogisticRegression] Epoch 20 (40.82s)\tAverage loss=0.660065\tDev F1=76.28\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 29 (64.76s)\tAverage loss=0.676497\tDev F1=80.00\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Training done (65.35s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\SparseLogisticRegression\\SparseLogisticRegression-29\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1 Score: 0.8\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_2>\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression_best>\n",
      "============================================================\n",
      "[4] Testing batch_size = 64, lr = 1.00e-02, l1_penalty = 1.00e-02, l2_penalty = 1.00e-02, rebalance = 0.00e+00\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3585  #epochs=30  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (6.51s)\tAverage loss=8.208689\tDev F1=74.26\n",
      "[SparseLogisticRegression] Epoch 10 (43.17s)\tAverage loss=1.243412\tDev F1=81.68\n",
      "[SparseLogisticRegression] Epoch 20 (92.38s)\tAverage loss=1.298887\tDev F1=80.00\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 29 (129.14s)\tAverage loss=1.266789\tDev F1=77.24\n",
      "[SparseLogisticRegression] Training done (129.16s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\SparseLogisticRegression\\SparseLogisticRegression-20\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1 Score: 0.8\n",
      "============================================================\n",
      "[5] Testing batch_size = 64, lr = 1.00e-02, l1_penalty = 1.00e-06, l2_penalty = 1.00e-06, rebalance = 5.00e-01\n",
      "============================================================\n",
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3288  #epochs=30  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (2.86s)\tAverage loss=0.736663\tDev F1=64.42\n",
      "[SparseLogisticRegression] Epoch 10 (29.54s)\tAverage loss=0.748437\tDev F1=68.93\n",
      "[SparseLogisticRegression] Epoch 20 (55.47s)\tAverage loss=0.735418\tDev F1=76.19\n",
      "[SparseLogisticRegression] Model saved as <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] Epoch 29 (81.56s)\tAverage loss=0.739645\tDev F1=75.00\n",
      "[SparseLogisticRegression] Training done (81.61s)\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\SparseLogisticRegression\\SparseLogisticRegression-20\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression>\n",
      "[SparseLogisticRegression] F-1 Score: 0.761904761904762\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\grid_search\\SparseLogisticRegression_2\\SparseLogisticRegression_2-0\n",
      "[SparseLogisticRegression] Loaded model <SparseLogisticRegression_2>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>l1_penalty</th>\n",
       "      <th>l2_penalty</th>\n",
       "      <th>rebalance</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.798354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.684685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size      lr  l1_penalty  l2_penalty  rebalance     Prec.      Rec.  \\\n",
       "2         128  0.0100    0.000001    0.000100        0.0  0.830189  0.771930   \n",
       "3          64  0.0100    0.010000    0.010000        0.0  0.723404  0.894737   \n",
       "1          64  0.0010    0.000100    0.010000        0.5  0.751938  0.850877   \n",
       "4          64  0.0100    0.000001    0.000001        0.5  0.752137  0.771930   \n",
       "0          64  0.0001    0.000001    0.000100        0.0  0.703704  0.666667   \n",
       "\n",
       "        F-1  \n",
       "2  0.800000  \n",
       "3  0.800000  \n",
       "1  0.798354  \n",
       "4  0.761905  \n",
       "0  0.684685  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.learning import RandomSearch\n",
    "from snorkel.learning.tensorflow import SparseLogisticRegression\n",
    "\n",
    "seed = 1234\n",
    "num_model_search = 5\n",
    "\n",
    "# search over this parameter grid\n",
    "param_grid = {}\n",
    "param_grid['batch_size'] = [64, 128]\n",
    "param_grid['lr']         = [1e-4, 1e-3, 1e-2]\n",
    "param_grid['l1_penalty'] = [1e-6, 1e-4, 1e-2]\n",
    "param_grid['l2_penalty'] = [1e-6, 1e-4, 1e-2]\n",
    "param_grid['rebalance']  = [0.0, 0.5]\n",
    "\n",
    "model_class_params = {\n",
    "    'n_threads':1\n",
    "}\n",
    "\n",
    "model_hyperparams = {\n",
    "    'n_epochs': 30,\n",
    "    'print_freq': 10,\n",
    "    'dev_ckpt_delay': 0.5,\n",
    "    'X_dev': F_dev,\n",
    "    'Y_dev': L_gold_dev\n",
    "}\n",
    "\n",
    "searcher = RandomSearch(SparseLogisticRegression, param_grid, F_train, train_marginals,\n",
    "                        n=num_model_search, seed=seed,\n",
    "                        model_class_params=model_class_params,\n",
    "                        model_hyperparams=model_hyperparams)\n",
    "\n",
    "print(\"Discriminitive Model Parameter Space (seed={}):\".format(seed))\n",
    "for i, params in enumerate(searcher.search_space()):\n",
    "    print(\"{} {}\".format(i, params))\n",
    "\n",
    "disc_model, run_stats = searcher.fit(X_valid=F_dev, Y_valid=L_gold_dev, n_threads=1)\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erica\\Anaconda3\\envs\\snorkel\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseLogisticRegression] Training model\n",
      "[SparseLogisticRegression] n_train=3585  #epochs=30  batch size=64\n",
      "[SparseLogisticRegression] Epoch 0 (5.09s)\tAverage loss=3.730745\n",
      "[SparseLogisticRegression] Epoch 10 (37.81s)\tAverage loss=4.923562\n",
      "[SparseLogisticRegression] Epoch 20 (71.60s)\tAverage loss=5.155086\n",
      "[SparseLogisticRegression] Epoch 29 (104.67s)\tAverage loss=5.454622\n",
      "[SparseLogisticRegression] Training done (104.67s)\n"
     ]
    }
   ],
   "source": [
    "# Just the best model\n",
    "from snorkel.learning.tensorflow import SparseLogisticRegression\n",
    "\n",
    "log_reg = SparseLogisticRegression()\n",
    "\n",
    "log_reg.train(\n",
    "    X_train = F_train, Y_train = train_marginals, \n",
    "    lr = 0.1,\n",
    "    batch_size = 64,\n",
    "    l1_penalty = 1.00e-06,\n",
    "    l2_penalty = 1.00e-04,\n",
    "    rebalance = 0.0,\n",
    "    n_threads = 1,\n",
    "    n_epochs = 30,\n",
    "    print_freq = 10,\n",
    "    dev_ckpt_delay = 0.5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec, Recall, F1 scores\n",
      "[0.794 0.746 0.769]\n",
      "[0.19  0.811 0.308]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('Prec, Recall, F1 scores')\n",
    "print(np.round(log_reg.score(F_dev, L_gold_dev), 3)) # dev set\n",
    "print(np.round((log_reg.score(F_test, L_gold_test)), 3)) # test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52127\n",
      "[-0.5328904, 'WIN_RIGHT_SEQ_LEMMAS[( je]']\n",
      "[-0.46939763, 'WIN_LEFT_SEQ_LEMMAS[neutralization of]']\n",
      "[-0.4480359, 'WIN_LEFT_LEMMAS[.70%]']\n",
      "[-0.43169013, 'WIN_RIGHT_SEQ_LEMMAS[fever (]']\n",
      "[-0.42790008, 'WIN_RIGHT_SEQ_POS_TAGS[NNP -RRB- VBN]']\n",
      "[-0.42789805, 'WIN_RIGHT_SEQ_LEMMAS[) report]']\n",
      "[-0.42785242, 'WIN_RIGHT_SEQ_LEMMAS[( chik]']\n",
      "[-0.42784595, 'WIN_RIGHT_SEQ_LEMMAS[fever ( chik]']\n",
      "[-0.42782688, 'WIN_RIGHT_SEQ_LEMMAS[chik ) report]']\n",
      "[-0.4278252, 'WIN_RIGHT_SEQ_LEMMAS[chik )]']\n",
      "[-0.42781186, 'WIN_RIGHT_SEQ_LEMMAS[( chik )]']\n",
      "[-0.42696872, 'WIN_RIGHT_SEQ_LEMMAS[je ) ,]']\n",
      "[-0.42696062, 'WIN_RIGHT_SEQ_LEMMAS[( je )]']\n",
      "[-0.426956, 'WIN_RIGHT_SEQ_LEMMAS[je )]']\n",
      "[-0.4224598, 'BETWEEN_SEQ_LEMMAS[be retest]']\n",
      "[-0.40965173, 'WIN_LEFT_SEQ_LEMMAS[with .70% neutralization]']\n",
      "[-0.4094547, 'WIN_LEFT_SEQ_LEMMAS[with .70%]']\n",
      "[-0.4091316, 'BETWEEN_LEMMAS[retest]']\n",
      "[-0.40907568, 'BETWEEN_SEQ_LEMMAS[be retest through]']\n",
      "[-0.4080431, 'WIN_LEFT_SEQ_LEMMAS[sample with .70%]']\n",
      "[-0.40576074, 'BETWEEN_SEQ_LEMMAS[through a]']\n",
      "[-0.40477282, 'WIN_LEFT_SEQ_LEMMAS[sample with]']\n",
      "[-0.40129438, 'BETWEEN_SEQ_LEMMAS[second jev]']\n",
      "[-0.3990984, 'BETWEEN_SEQ_LEMMAS[retest through a]']\n",
      "[-0.3986739, 'WIN_LEFT_LEMMAS[1:10]']\n",
      "[-0.3981686, 'WIN_LEFT_SEQ_LEMMAS[.70% neutralization of]']\n",
      "[-0.3973004, 'WIN_LEFT_SEQ_LEMMAS[.70% neutralization]']\n",
      "[-0.3951945, 'WIN_LEFT_SEQ_LEMMAS[1:10 dilution for]']\n",
      "[-0.395192, 'BETWEEN_SEQ_LEMMAS[a second jev]']\n",
      "[-0.39307317, 'WIN_LEFT_SEQ_LEMMAS[1:10 dilution]']\n",
      "[-0.39247635, 'WIN_LEFT_SEQ_LEMMAS[dilution for]']\n",
      "[-0.3917606, 'WIN_LEFT_SEQ_LEMMAS[dilution for antibody]']\n",
      "[-0.39174232, 'BETWEEN_LEMMAS[through]']\n",
      "[-0.39119992, 'BETWEEN_LEMMAS[nestling]']\n",
      "[-0.39061183, 'BETWEEN_SEQ_LEMMAS[retest through]']\n",
      "[-0.38861826, 'WIN_LEFT_LEMMAS[dilution]']\n",
      "[-0.38609064, 'WIN_LEFT_SEQ_LEMMAS[for antibody to]']\n",
      "[-0.38004628, 'BETWEEN_SEQ_LEMMAS[jev prnt for]']\n",
      "[-0.37017384, 'BETWEEN_SEQ_LEMMAS[through a second]']\n",
      "[-0.36882654, 'BETWEEN_SEQ_LEMMAS[jev prnt]']\n",
      "[-0.36639532, 'BETWEEN_SEQ_LEMMAS[a second]']\n",
      "[-0.36224353, 'BETWEEN_SEQ_LEMMAS[second jev prnt]']\n",
      "[-0.34973192, 'WIN_LEFT_SEQ_POS_TAGS[NNS IN CD]']\n",
      "[-0.31221324, 'WIN_LEFT_SEQ_POS_TAGS[IN CD NN]']\n",
      "[-0.3062049, 'BETWEEN_LEMMAS[second]']\n",
      "[-0.28777274, 'BETWEEN_LEMMAS[not]']\n",
      "[-0.28579262, 'WIN_LEFT_SEQ_LEMMAS[usa ) and]']\n",
      "[-0.28552383, 'BETWEEN_LEMMAS[additional]']\n",
      "[-0.2792967, 'BETWEEN_SEQ_POS_TAGS[NNP NNP IN]']\n",
      "[-0.2770962, 'WIN_LEFT_SEQ_POS_TAGS[CD NN IN]']\n",
      "--------------------\n",
      "[0.25411457, 'WIN_RIGHT_SEQ_LEMMAS[hemorrhagic fever]']\n",
      "[0.26037288, 'WIN_RIGHT_SEQ_POS_TAGS[NNP JJ NN]']\n",
      "[0.26048824, 'WIN_RIGHT_SEQ_POS_TAGS[-RRB- IN NN]']\n",
      "[0.26331463, 'BETWEEN_SEQ_POS_TAGS[-RRB- , JJ]']\n",
      "[0.26342613, 'WIN_RIGHT_SEQ_POS_TAGS[NNP NN JJ]']\n",
      "[0.26775575, 'BETWEEN_SEQ_POS_TAGS[NNP IN JJ]']\n",
      "[0.26928356, 'WIN_RIGHT_LEMMAS[russia]']\n",
      "[0.27293417, 'WIN_RIGHT_SEQ_POS_TAGS[VBN NNP NN]']\n",
      "[0.27417704, 'WIN_RIGHT_SEQ_LEMMAS[north -]']\n",
      "[0.27632064, 'WIN_RIGHT_SEQ_LEMMAS[in north -]']\n",
      "[0.27661255, 'WIN_RIGHT_SEQ_LEMMAS[north - west]']\n",
      "[0.27689457, 'WIN_RIGHT_SEQ_POS_TAGS[IN NN HYPH]']\n",
      "[0.27713004, 'WIN_RIGHT_SEQ_LEMMAS[- west]']\n",
      "[0.3109794, 'WIN_RIGHT_SEQ_LEMMAS[strain name tembusu]']\n",
      "[0.3112471, 'WIN_RIGHT_SEQ_LEMMAS[tembusu virus]']\n",
      "[0.3113582, 'WIN_RIGHT_SEQ_LEMMAS[tembusu virus fengxian]']\n",
      "[0.3120946, 'WIN_RIGHT_SEQ_LEMMAS[virus fengxian]']\n",
      "[0.31217036, 'WIN_RIGHT_SEQ_LEMMAS[name tembusu]']\n",
      "[0.31337664, 'WIN_RIGHT_SEQ_LEMMAS[strain name]']\n",
      "[0.31375477, 'WIN_RIGHT_SEQ_LEMMAS[name tembusu virus]']\n",
      "[0.32258448, 'WIN_RIGHT_SEQ_POS_TAGS[NN VBN NNP]']\n",
      "[0.32371375, 'WIN_RIGHT_SEQ_LEMMAS[31–40 �41 total]']\n",
      "[0.3268562, 'BETWEEN_SEQ_POS_TAGS[NN IN DT]']\n",
      "[0.3285933, 'BETWEEN_SEQ_LEMMAS[japanese encephalitis zika]']\n",
      "[0.32871178, 'WIN_RIGHT_SEQ_LEMMAS[( denrocopos major]']\n",
      "[0.328739, 'WIN_RIGHT_SEQ_LEMMAS[( denrocopos]']\n",
      "[0.32874885, 'WIN_RIGHT_SEQ_LEMMAS[denrocopos major )]']\n",
      "[0.32875502, 'WIN_RIGHT_LEMMAS[denrocopos]']\n",
      "[0.32879004, 'WIN_RIGHT_SEQ_LEMMAS[denrocopos major]']\n",
      "[0.33011445, 'BETWEEN_SEQ_LEMMAS[encephalitis zika]']\n",
      "[0.3434359, 'BETWEEN_LEMMAS[encephalitis]']\n",
      "[0.34942275, 'WIN_LEFT_LEMMAS[communication]']\n",
      "[0.3497812, 'WIN_LEFT_SEQ_POS_TAGS[VBZ NNP NNP]']\n",
      "[0.34979567, 'WIN_LEFT_SEQ_LEMMAS[short communication detection]']\n",
      "[0.3498711, 'WIN_LEFT_SEQ_LEMMAS[short communication]']\n",
      "[0.35009208, 'WIN_LEFT_SEQ_LEMMAS[l short communication]']\n",
      "[0.35010058, 'WIN_LEFT_LEMMAS[short]']\n",
      "[0.35041395, 'WIN_LEFT_SEQ_LEMMAS[communication detection of]']\n",
      "[0.35047826, 'WIN_LEFT_SEQ_LEMMAS[l short]']\n",
      "[0.35051066, 'WIN_LEFT_LEMMAS[l]']\n",
      "[0.350767, 'WIN_LEFT_SEQ_LEMMAS[communication detection]']\n",
      "[0.35085914, 'WIN_LEFT_SEQ_POS_TAGS[VBZ NNP]']\n",
      "[0.35390964, 'WIN_RIGHT_SEQ_LEMMAS[�41 total]']\n",
      "[0.58167946, 'BETWEEN_SEQ_LEMMAS[dengue-2 japanese]']\n",
      "[0.5831777, 'WIN_RIGHT_SEQ_LEMMAS[31–40 �41]']\n",
      "[0.58874565, 'WIN_RIGHT_LEMMAS[�41]']\n",
      "[0.6168815, 'BETWEEN_SEQ_LEMMAS[to dengue-2 japanese]']\n",
      "[0.62111276, 'WIN_RIGHT_SEQ_LEMMAS[21–30 31–40 �41]']\n",
      "[0.6220015, 'BETWEEN_SEQ_LEMMAS[dengue-2 japanese encephalitis]']\n"
     ]
    }
   ],
   "source": [
    "# Extracting features allows us to inspect and interperet our learned weights\n",
    "from scoring import *\n",
    "print_top_k_features(session, disc_model, F_train, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prec: 0.190, Recall: 0.811, F1 Score: 0.308\n"
     ]
    }
   ],
   "source": [
    "# performance on the test set\n",
    "p, r, f1 = log_reg.score(X_test = F_test, Y_test = L_gold_test)\n",
    "print(\"Prec: {0:.3f}, Recall: {1:.3f}, F1 Score: {2:.3f}\".format(p, r, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.811\n",
      "Neg. class accuracy: 0.606\n",
      "Precision            0.19\n",
      "Recall               0.811\n",
      "F1                   0.308\n",
      "----------------------------------------\n",
      "TP: 30 | FP: 128 | TN: 197 | FN: 7\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp, fp, tn, fn = log_reg.error_analysis(session, F_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.undef('viewer');\n",
       "\n",
       "// NOTE: all elements should be selected using this.$el.find to avoid collisions with other Viewers\n",
       "\n",
       "define('viewer', [\"@jupyter-widgets/base\"], function(widgets) {\n",
       "    var ViewerView = widgets.DOMWidgetView.extend({\n",
       "        render: function() {\n",
       "            this.cids   = this.model.get('cids');\n",
       "            this.nPages = this.cids.length;\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Insert the html payload\n",
       "            this.$el.append(this.model.get('html'));\n",
       "\n",
       "            // Initialize all labels from previous sessions\n",
       "            this.labels = this.deserializeDict(this.model.get('_labels_serialized'));\n",
       "            for (var i=0; i < this.nPages; i++) {\n",
       "                this.pid = i;\n",
       "                for (var j=0; j < this.cids[i].length; j++) {\n",
       "                    this.cxid = j;\n",
       "                    for (var k=0; k < this.cids[i][j].length; k++) {\n",
       "                        this.cid = k;\n",
       "                        if (this.cids[i][j][k] in this.labels) {\n",
       "                            this.markCurrentCandidate(false);\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            }\n",
       "            this.pid  = 0;\n",
       "            this.cxid = 0;\n",
       "            this.cid  = 0;\n",
       "\n",
       "            // Enable button functionality for navigation\n",
       "            var that = this;\n",
       "            this.$el.find(\"#next-cand\").click(function() {\n",
       "                that.switchCandidate(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-cand\").click(function() {\n",
       "                that.switchCandidate(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-context\").click(function() {\n",
       "                that.switchContext(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-context\").click(function() {\n",
       "                that.switchContext(-1);\n",
       "            });\n",
       "            this.$el.find(\"#next-page\").click(function() {\n",
       "                that.switchPage(1);\n",
       "            });\n",
       "            this.$el.find(\"#prev-page\").click(function() {\n",
       "                that.switchPage(-1);\n",
       "            });\n",
       "            this.$el.find(\"#label-true\").click(function() {\n",
       "                that.labelCandidate(true, true);\n",
       "            });\n",
       "            this.$el.find(\"#label-false\").click(function() {\n",
       "                that.labelCandidate(false, true);\n",
       "            });\n",
       "\n",
       "            // Arrow key functionality\n",
       "            this.$el.keydown(function(e) {\n",
       "                switch(e.which) {\n",
       "                    case 74: // j\n",
       "                    that.switchCandidate(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 73: // i\n",
       "                    that.switchPage(-1);\n",
       "                    break;\n",
       "\n",
       "                    case 76: // l\n",
       "                    that.switchCandidate(1);\n",
       "                    break;\n",
       "\n",
       "                    case 75: // k\n",
       "                    that.switchPage(1);\n",
       "                    break;\n",
       "\n",
       "                    case 84: // t\n",
       "                    that.labelCandidate(true, true);\n",
       "                    break;\n",
       "\n",
       "                    case 70: // f\n",
       "                    that.labelCandidate(false, true);\n",
       "                    break;\n",
       "                }\n",
       "            });\n",
       "\n",
       "            // Show the first page and highlight the first candidate\n",
       "            this.$el.find(\"#viewer-page-0\").show();\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Get candidate selector for currently selected candidate, escaping id properly\n",
       "        getCandidate: function() {\n",
       "            return this.$el.find(\".\"+this.cids[this.pid][this.cxid][this.cid]);\n",
       "        },  \n",
       "\n",
       "        // Color the candidate correctly according to registered label, as well as set highlighting\n",
       "        markCurrentCandidate: function(highlight) {\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var tags = this.$el.find(\".\"+cid);\n",
       "\n",
       "            // Clear color classes\n",
       "            tags.removeClass(\"candidate-h\");\n",
       "            tags.removeClass(\"true-candidate\");\n",
       "            tags.removeClass(\"true-candidate-h\");\n",
       "            tags.removeClass(\"false-candidate\");\n",
       "            tags.removeClass(\"false-candidate-h\");\n",
       "            tags.removeClass(\"highlighted\");\n",
       "\n",
       "            if (highlight) {\n",
       "                if (cid in this.labels) {\n",
       "                    tags.addClass(String(this.labels[cid]) + \"-candidate-h\");\n",
       "                } else {\n",
       "                    tags.addClass(\"candidate-h\");\n",
       "                }\n",
       "            \n",
       "            // If un-highlighting, leave with first non-null coloring\n",
       "            } else {\n",
       "                var that = this;\n",
       "                tags.each(function() {\n",
       "                    var cids = $(this).attr('class').split(/\\s+/).map(function(item) {\n",
       "                        return parseInt(item);\n",
       "                    });\n",
       "                    cids.sort();\n",
       "                    for (var i in cids) {\n",
       "                        if (cids[i] in that.labels) {\n",
       "                            var label = that.labels[cids[i]];\n",
       "                            $(this).addClass(String(label) + \"-candidate\");\n",
       "                            $(this).removeClass(String(!label) + \"-candidate\");\n",
       "                            break;\n",
       "                        }\n",
       "                    }\n",
       "                });\n",
       "            }\n",
       "\n",
       "            // Extra highlighting css\n",
       "            if (highlight) {\n",
       "                tags.addClass(\"highlighted\");\n",
       "            }\n",
       "\n",
       "            // Classes for showing direction of relation\n",
       "            if (highlight) {\n",
       "                this.$el.find(\".\"+cid+\"-0\").addClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").addClass(\"right-candidate\");\n",
       "            } else {\n",
       "                this.$el.find(\".\"+cid+\"-0\").removeClass(\"left-candidate\");\n",
       "                this.$el.find(\".\"+cid+\"-1\").removeClass(\"right-candidate\");\n",
       "            }\n",
       "        },\n",
       "\n",
       "        // Cycle through candidates and highlight, by increment inc\n",
       "        switchCandidate: function(inc) {\n",
       "            var N = this.cids[this.pid].length\n",
       "            var M = this.cids[this.pid][this.cxid].length;\n",
       "            if (N == 0 || M == 0) { return false; }\n",
       "\n",
       "            // Clear highlighting from previous candidate\n",
       "            if (inc != 0) {\n",
       "                this.markCurrentCandidate(false);\n",
       "\n",
       "                // Increment the cid counter\n",
       "\n",
       "                // Move to next context\n",
       "                if (this.cid + inc >= M) {\n",
       "                    while (this.cid + inc >= M) {\n",
       "                        \n",
       "                        // At last context on page, halt\n",
       "                        if (this.cxid == N - 1) {\n",
       "                            this.cid = M - 1;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to next context\n",
       "                        } else {\n",
       "                            inc -= M - this.cid;\n",
       "                            this.cxid += 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = 0;\n",
       "                        }\n",
       "                    }\n",
       "\n",
       "                // Move to previous context\n",
       "                } else if (this.cid + inc < 0) {\n",
       "                    while (this.cid + inc < 0) {\n",
       "                        \n",
       "                        // At first context on page, halt\n",
       "                        if (this.cxid == 0) {\n",
       "                            this.cid = 0;\n",
       "                            inc = 0;\n",
       "                            break;\n",
       "                        \n",
       "                        // Increment to previous context\n",
       "                        } else {\n",
       "                            inc += this.cid + 1;\n",
       "                            this.cxid -= 1;\n",
       "                            M = this.cids[this.pid][this.cxid].length;\n",
       "                            this.cid = M - 1;\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "\n",
       "                // Move within current context\n",
       "                this.cid += inc;\n",
       "            }\n",
       "            this.markCurrentCandidate(true);\n",
       "\n",
       "            // Push this new cid to the model\n",
       "            this.model.set('_selected_cid', this.cids[this.pid][this.cxid][this.cid]);\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Switch through contexts\n",
       "        switchContext: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "\n",
       "            // Iterate context on this page\n",
       "            var M = this.cids[this.pid].length;\n",
       "            if (this.cxid + inc < 0) {\n",
       "                this.cxid = 0;\n",
       "            } else if (this.cxid + inc >= M) {\n",
       "                this.cxid = M - 1;\n",
       "            } else {\n",
       "                this.cxid += inc;\n",
       "            }\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Switch through pages\n",
       "        switchPage: function(inc) {\n",
       "            this.markCurrentCandidate(false);\n",
       "            this.$el.find(\".viewer-page\").hide();\n",
       "            if (this.pid + inc < 0) {\n",
       "                this.pid = 0;\n",
       "            } else if (this.pid + inc > this.nPages - 1) {\n",
       "                this.pid = this.nPages - 1;\n",
       "            } else {\n",
       "                this.pid += inc;\n",
       "            }\n",
       "            this.$el.find(\"#viewer-page-\"+this.pid).show();\n",
       "\n",
       "            // Show pagination\n",
       "            this.$el.find(\"#page\").html(this.pid);\n",
       "\n",
       "            // Reset cid and set to first candidate\n",
       "            this.cid = 0;\n",
       "            this.cxid = 0;\n",
       "            this.switchCandidate(0);\n",
       "        },\n",
       "\n",
       "        // Label currently-selected candidate\n",
       "        labelCandidate: function(label, highlighted) {\n",
       "            var c    = this.getCandidate();\n",
       "            var cid  = this.cids[this.pid][this.cxid][this.cid];\n",
       "            var cl   = String(label) + \"-candidate\";\n",
       "            var clh  = String(label) + \"-candidate-h\";\n",
       "            var cln  = String(!label) + \"-candidate\";\n",
       "            var clnh = String(!label) + \"-candidate-h\";\n",
       "\n",
       "            // Toggle label highlighting\n",
       "            if (c.hasClass(cl) || c.hasClass(clh)) {\n",
       "                c.removeClass(cl);\n",
       "                c.removeClass(clh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(\"candidate-h\");\n",
       "                }\n",
       "                this.labels[cid] = null;\n",
       "                this.send({event: 'delete_label', cid: cid});\n",
       "            } else {\n",
       "                c.removeClass(cln);\n",
       "                c.removeClass(clnh);\n",
       "                if (highlighted) {\n",
       "                    c.addClass(clh);\n",
       "                } else {\n",
       "                    c.addClass(cl);\n",
       "                }\n",
       "                this.labels[cid] = label;\n",
       "                this.send({event: 'set_label', cid: cid, value: label});\n",
       "            }\n",
       "\n",
       "            // Set the label and pass back to the model\n",
       "            this.model.set('_labels_serialized', this.serializeDict(this.labels));\n",
       "            this.touch();\n",
       "        },\n",
       "\n",
       "        // Serialization of hash maps, because traitlets Dict doesn't seem to work...\n",
       "        serializeDict: function(d) {\n",
       "            var s = [];\n",
       "            for (var key in d) {\n",
       "                s.push(key+\"~~\"+d[key]);\n",
       "            }\n",
       "            return s.join();\n",
       "        },\n",
       "\n",
       "        // Deserialization of hash maps\n",
       "        deserializeDict: function(s) {\n",
       "            var d = {};\n",
       "            var entries = s.split(/,/);\n",
       "            var kv;\n",
       "            for (var i in entries) {\n",
       "                kv = entries[i].split(/~~/);\n",
       "                if (kv[1] == \"true\") {\n",
       "                    d[kv[0]] = true;\n",
       "                } else if (kv[1] == \"false\") {\n",
       "                    d[kv[0]] = false;\n",
       "                }\n",
       "            }\n",
       "            return d;\n",
       "        },\n",
       "    });\n",
       "\n",
       "    return {\n",
       "        ViewerView: ViewerView\n",
       "    };\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87f4faaa53f47578711f310f3a300e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SentenceNgramViewer(cids=[[[22], [26], [61, 62, 63, 64, 84, 85]], [[13, 73, 101], [17, 69, 80, 93], [54, 95]],…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view false positives\n",
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "SentenceNgramViewer(fp, session, height = 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A look at the test marginals:\n",
    "\n",
    "# save the predictions of the model on the test set back to the database\n",
    "disc_model.save_marginals(session, test_cands, training=False)\n",
    "\n",
    "# load marginals\n",
    "test_marginals = load_marginals(session, X=test_cands, split=2, training=False)\n",
    "\n",
    "# plot the test marginals\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(test_marginals, bins=20, range=(0.0, 1.0))\n",
    "plt.title('Distribution of Test Marginals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all candidates to csv file\n",
    "df = pd.DataFrame({'id': [], 'virus': [], 'host': []}) # initialize df w three columns\n",
    "\n",
    "# list all candidates (to export later and merge w predicted probabilities table?)\n",
    "for c in session.query(VirusHost).all():\n",
    "    df = df.append({'id': c.id, 'virus': c.virus.get_attrib_tokens(\"words\"), 'host': c.host.get_attrib_tokens(\"words\")}, ignore_index=True)\n",
    "    \n",
    "df2 = df[:] # make a copy of the df\n",
    "df2['virus'] = df['virus'].str.join(' ')\n",
    "df2['host'] = df['host'].str.join(' ')\n",
    "df2['virus'] = df2['virus'].str.replace('[^a-zA-Z ]', '') # remove non alphaetic characters\n",
    "df2['host'] = df2['host'].str.replace('[^a-zA-Z ]', '')\n",
    "df2['id'] = df['id'].astype('int64') \n",
    "df2.to_csv('candidates.csv', index = False)  # exports the candidates to a file called candidates.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel!)",
   "language": "python",
   "name": "snorkel"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
