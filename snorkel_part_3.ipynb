{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virus-Host Species Relation Extraction\n",
    "## Notebook 3 - Generative Model Training\n",
    "### UC Davis Epicenter for Disease Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<430x1 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 126 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Connect to the database backend and initalize a Snorkel session\n",
    "#from lib.init import *\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "VirusHost = candidate_subclass('VirusHost', ['virus', 'host'])\n",
    "\n",
    "# gold (human-labeled) development set labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Fitting a Generative Model\n",
    "Generative models estimate joint probability of x and y in order to generate new data.\n",
    "<br>\n",
    "<br>\n",
    "In our case, the Generative Model will unify weak sources (the individual LFs) by maximizing the marginal likelihood of the LFs to learn model parameters. We estimate the accuracy of each LF.\n",
    "<br>\n",
    "<br>\n",
    "Intuitively, the labeling functions are modeled based on how much they agree or disagree with each other. Once the model is trained, the outputs of the LFs are combined into a single, noise-aware training label set (called 'train_marginals') for our end extractor (the discriminative model, an LSTM network). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load label matrices from notebook 2\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "\n",
    "labeler = LabelAnnotator(lfs = [])\n",
    "L_train = labeler.load_matrix(session, split=0)\n",
    "L_dev = labeler.load_matrix(session, split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Model\n",
    "According to data programming, the generative model is used as a more sophisticated way to unify lower quality labeling functions. Since our labeling functions will not be perfect classifiers (some may be low-quality) their accuracies are modeled. \n",
    "<br>\n",
    "<br>\n",
    "**End goal**: produce a single set of denoised **training labels**, which are then used to train an end extraction model (LSTM) in Notebook 4. \n",
    "<br>\n",
    "<br>\n",
    "**Parameter Definitions**\n",
    "<br>\n",
    "epochs:     A single pass through all the data in your training set\n",
    "<br>\n",
    "step_size:  The factor by which we update model weights after computing the gradient\n",
    "<br>\n",
    "decay:      The rate our update factor dimishes (decay) over time.\n",
    "<br>\n",
    "<br>\n",
    "While training the model, we should include dependencies between LFs that may affect output. The DependencySelector function identifies a set of likely dependencies for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect dependencies between LFs\n",
    "from snorkel.learning.structure import DependencySelector\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold = 0.1)\n",
    "len(deps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing different hyperparameters to find the best accuracy\n",
    "We use a grid search to tune hyperparameters, optimizing the model\n",
    "<br>\n",
    "<br>\n",
    "#### Definitions:\n",
    "- **Precision**: How often is the model correct when it predicts positive? \n",
    "<br>\n",
    "<br>\n",
    "$$Precision = \\frac{truepositives}{truepositives + falsepositives}$$\n",
    "<br>\n",
    "<br>\n",
    "- **Recall**: Helps when the cost of false negatives is high. A lower recall means there are more false negatives.\n",
    "<br>\n",
    "<br>\n",
    "$$Recall = \\frac{truepositives}{truepositives + falsenegatives}$$\n",
    "<br>\n",
    "<br>\n",
    "- **F-1**: Overall measure of a model's accuracy, combining precision and recall. A good F-1 score means low false positives and low false negatives. The higher the score, the better (a perfect model having F-1 score of 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[1] Testing step_size = 1.00e-05, decay = 9.00e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.42811501597444096\n",
      "[GenerativeModel] Model saved as <GenerativeModel_0>.\n",
      "[GenerativeModel] Model saved as <GenerativeModel_best>.\n",
      "============================================================\n",
      "[2] Testing step_size = 2.62e-05, decay = 9.50e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.42811501597444096\n",
      "============================================================\n",
      "[3] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.42811501597444096\n",
      "============================================================\n",
      "[4] Testing step_size = 1.00e-04, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.42948717948717946\n",
      "[GenerativeModel] Model saved as <GenerativeModel_3>.\n",
      "[GenerativeModel] Model saved as <GenerativeModel_best>.\n",
      "============================================================\n",
      "[5] Testing step_size = 1.00e-06, decay = 9.50e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.42811501597444096\n",
      "[GenerativeModel] Model <GenerativeModel_3> loaded.\n",
      "Wall time: 1min 47s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_size</th>\n",
       "      <th>decay</th>\n",
       "      <th>epochs</th>\n",
       "      <th>reg_param</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.286325</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.429487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.285106</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.428115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.95</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.285106</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.428115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.285106</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.428115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.95</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.285106</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.428115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step_size  decay  epochs  reg_param     Prec.      Rec.       F-1\n",
       "3   0.000100   0.90     100      0.001  0.286325  0.858974  0.429487\n",
       "0   0.000010   0.90      50      0.001  0.285106  0.858974  0.428115\n",
       "1   0.000026   0.95     100      0.001  0.285106  0.858974  0.428115\n",
       "2   0.000010   0.95      50      0.001  0.285106  0.858974  0.428115\n",
       "4   0.000001   0.95     100      0.001  0.285106  0.858974  0.428115"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning import RandomSearch\n",
    "\n",
    "param_ranges = {\n",
    "    'step_size' : [1e-3, 1e-4, 1e-5, 1e-6, 0.1/L_train.shape[0]],\n",
    "    'decay'     : [0.9, 0.95],\n",
    "    'epochs'    : [50, 100],\n",
    "    'reg_param' : [1e-3],\n",
    "}\n",
    "\n",
    "model_class_params = {'lf_propensity' : True}\n",
    "\n",
    "searcher = RandomSearch(GenerativeModel, param_ranges, L_train, n=5, model_class_params=model_class_params)\n",
    "%time gen_model, run_stats = searcher.fit(L_dev, L_gold_dev)\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The searcher selected the optimal model. Let's rerun the model, this time with the optimal hyperparameters and including dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n"
     ]
    }
   ],
   "source": [
    "# Run the model, using deps to include the learned dependencies between LFs\n",
    "\n",
    "# LF propensity set to True, which learns the likelihood of labeling an example\n",
    "gen_model = GenerativeModel(lf_propensity = True)\n",
    "gen_model.train(\n",
    "    L_train, deps=deps, decay=0.90, epochs=100, step_size=1.00e-04, reg_param=1.00e-03\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The marginal predictions of the training labels\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3823"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_marginals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visually explore the distribution of predicted training marginals. \n",
    "<br>\n",
    "**Ideally, there should get a bimodal distribution with large separation between each peaks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20, range=(0.0, 1.0))\n",
    "plt.title('Distribution of Training Marginals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The X axis is probability of classifying as positive or negative label (So a 0.5 would not be classified as anything). Based on shape above, ideally there are more values on the ends which indicate good coverage on both the positive and negative side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_detect</th>\n",
       "      <td>0</td>\n",
       "      <td>0.061732</td>\n",
       "      <td>0.061732</td>\n",
       "      <td>0.017002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_infect</th>\n",
       "      <td>1</td>\n",
       "      <td>0.052838</td>\n",
       "      <td>0.052838</td>\n",
       "      <td>0.016479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_isolate</th>\n",
       "      <td>2</td>\n",
       "      <td>0.070102</td>\n",
       "      <td>0.070102</td>\n",
       "      <td>0.023280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive</th>\n",
       "      <td>3</td>\n",
       "      <td>0.164269</td>\n",
       "      <td>0.164269</td>\n",
       "      <td>0.046822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.046037</td>\n",
       "      <td>0.046037</td>\n",
       "      <td>0.008370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_misc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.251112</td>\n",
       "      <td>0.251112</td>\n",
       "      <td>0.148313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_cause_h</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>0.001308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_h</th>\n",
       "      <td>7</td>\n",
       "      <td>0.295318</td>\n",
       "      <td>0.152760</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_h_v</th>\n",
       "      <td>8</td>\n",
       "      <td>0.174470</td>\n",
       "      <td>0.062255</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_other_verbs</th>\n",
       "      <td>9</td>\n",
       "      <td>0.047607</td>\n",
       "      <td>0.047607</td>\n",
       "      <td>0.019880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_v_h</th>\n",
       "      <td>11</td>\n",
       "      <td>0.268899</td>\n",
       "      <td>0.232801</td>\n",
       "      <td>0.112477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_h_v</th>\n",
       "      <td>12</td>\n",
       "      <td>0.113523</td>\n",
       "      <td>0.092074</td>\n",
       "      <td>0.043421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_h</th>\n",
       "      <td>13</td>\n",
       "      <td>0.404918</td>\n",
       "      <td>0.325922</td>\n",
       "      <td>0.135757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_distant_supervision</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_assertions</th>\n",
       "      <td>15</td>\n",
       "      <td>0.084227</td>\n",
       "      <td>0.084227</td>\n",
       "      <td>0.012294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j  Coverage  Overlaps  Conflicts\n",
       "LF_detect                0  0.061732  0.061732   0.017002\n",
       "LF_infect                1  0.052838  0.052838   0.016479\n",
       "LF_isolate               2  0.070102  0.070102   0.023280\n",
       "LF_positive              3  0.164269  0.164269   0.046822\n",
       "LF_positive2             4  0.046037  0.046037   0.008370\n",
       "LF_misc                  5  0.251112  0.251112   0.148313\n",
       "LF_v_cause_h             6  0.005755  0.005755   0.001308\n",
       "LF_v_h                   7  0.295318  0.152760   0.003400\n",
       "LF_h_v                   8  0.174470  0.062255   0.000000\n",
       "LF_other_verbs           9  0.047607  0.047607   0.019880\n",
       "LF_uncertain            10  0.003400  0.003400   0.003400\n",
       "LF_far_v_h              11  0.268899  0.232801   0.112477\n",
       "LF_far_h_v              12  0.113523  0.092074   0.043421\n",
       "LF_neg_h                13  0.404918  0.325922   0.135757\n",
       "LF_distant_supervision  14  0.000523  0.000523   0.000000\n",
       "LF_neg_assertions       15  0.084227  0.084227   0.012294"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking performance against development set labels\n",
    "\n",
    "We will run the labeler on the development set, load in hand labels, then evaluate LF performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LF_detect</th>\n",
       "      <td>0</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_infect</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025581</td>\n",
       "      <td>0.025581</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_isolate</th>\n",
       "      <td>2</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive</th>\n",
       "      <td>3</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.060465</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_positive2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_misc</th>\n",
       "      <td>5</td>\n",
       "      <td>0.190698</td>\n",
       "      <td>0.190698</td>\n",
       "      <td>0.097674</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_cause_h</th>\n",
       "      <td>6</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_v_h</th>\n",
       "      <td>7</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.086047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_h_v</th>\n",
       "      <td>8</td>\n",
       "      <td>0.262791</td>\n",
       "      <td>0.083721</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_other_verbs</th>\n",
       "      <td>9</td>\n",
       "      <td>0.037209</td>\n",
       "      <td>0.037209</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_uncertain</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_v_h</th>\n",
       "      <td>11</td>\n",
       "      <td>0.155814</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.030233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_far_h_v</th>\n",
       "      <td>12</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0.034884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_h</th>\n",
       "      <td>13</td>\n",
       "      <td>0.090698</td>\n",
       "      <td>0.076744</td>\n",
       "      <td>0.051163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_distant_supervision</th>\n",
       "      <td>14</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LF_neg_assertions</th>\n",
       "      <td>15</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.032558</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j  Coverage  Overlaps  Conflicts  TP  FP  FN  TN  \\\n",
       "LF_detect                0  0.032558  0.032558   0.000000   6   3   0   0   \n",
       "LF_infect                1  0.025581  0.025581   0.002326   7   0   0   0   \n",
       "LF_isolate               2  0.002326  0.002326   0.000000   0   1   0   0   \n",
       "LF_positive              3  0.060465  0.060465   0.002326  13   4   0   0   \n",
       "LF_positive2             4  0.023256  0.023256   0.000000   4   1   0   0   \n",
       "LF_misc                  5  0.190698  0.190698   0.097674  22   5   0   0   \n",
       "LF_v_cause_h             6  0.004651  0.004651   0.000000   2   0   0   0   \n",
       "LF_v_h                   7  0.283721  0.086047   0.000000  31  11   0   0   \n",
       "LF_h_v                   8  0.262791  0.083721   0.002326  36   8   0   0   \n",
       "LF_other_verbs           9  0.037209  0.037209   0.006977   5   2   0   0   \n",
       "LF_uncertain            10  0.000000  0.000000   0.000000   0   0   0   0   \n",
       "LF_far_v_h              11  0.155814  0.032558   0.030233   0   0   2  19   \n",
       "LF_far_h_v              12  0.218605  0.034884   0.034884   0   0   1   5   \n",
       "LF_neg_h                13  0.090698  0.076744   0.051163   0   0  11   5   \n",
       "LF_distant_supervision  14  0.002326  0.002326   0.000000   0   0   0   0   \n",
       "LF_neg_assertions       15  0.032558  0.032558   0.009302   0   0   0   0   \n",
       "\n",
       "                        Empirical Acc.  \n",
       "LF_detect                     0.666667  \n",
       "LF_infect                     1.000000  \n",
       "LF_isolate                    0.000000  \n",
       "LF_positive                   0.764706  \n",
       "LF_positive2                  0.800000  \n",
       "LF_misc                       0.814815  \n",
       "LF_v_cause_h                  1.000000  \n",
       "LF_v_h                        0.738095  \n",
       "LF_h_v                        0.818182  \n",
       "LF_other_verbs                0.714286  \n",
       "LF_uncertain                       NaN  \n",
       "LF_far_v_h                    0.904762  \n",
       "LF_far_h_v                    0.833333  \n",
       "LF_neg_h                      0.312500  \n",
       "LF_distant_supervision             NaN  \n",
       "LF_neg_assertions                  NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.718\n",
      "Neg. class accuracy: 0.554\n",
      "Precision            0.263\n",
      "Recall               0.718\n",
      "F1                   0.385\n",
      "----------------------------------------\n",
      "TP: 56 | FP: 157 | TN: 195 | FN: 22\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generative Model Metrics\n",
    "dev_marginals = gen_model.marginals(L_dev)\n",
    "_ = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3823 marginals\n",
      "Wall time: 3.28 s\n"
     ]
    }
   ],
   "source": [
    "# Save training labels to use in end extraction model\n",
    "from snorkel.annotations import save_marginals\n",
    "%time save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel!)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
