{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virus-Host Species Relation Extraction\n",
    "## Notebook 3\n",
    "### UC Davis Epicenter for Disease Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "\n",
    "# Connect to the database backend and initalize a Snorkel session\n",
    "#from lib.init import *\n",
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "VirusHost = candidate_subclass('VirusHost', ['virus', 'host'])\n",
    "\n",
    "# gold (human-labeled) development set labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<102x1 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 89 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Fitting a Generative Model\n",
    "Now, we'll train a model of the LFs to estimate their accuracies. Once the model is trained, we can combine the outputs of the LFs into a single, noise-aware training label set for our extractor. Intuitively, we'll model the LFs by observing how they overlap and conflict with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load label matrices from notebook 2\n",
    "from snorkel.annotations import LabelAnnotator\n",
    "\n",
    "labeler = LabelAnnotator(lfs = [])\n",
    "L_train = labeler.load_matrix(session, split=0)\n",
    "L_dev = labeler.load_matrix(session, split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up and run the hyperparameter search, training our model with different hyperparamters and picking the best model configuration to keep. We'll set the random seed to maintain reproducibility.\n",
    "<br>\n",
    "Note that we are fitting our model's parameters to the training set generated by our labeling functions, while we are picking hyperparamters with respect to score over the development set labels which we created by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative ModelÂ¶\n",
    "In data programming, we use a more sophisticated model to unify our labeling functions. We know that these labeling functions will not be perfect, and some may be quite low-quality, so we will model their accuracies with a generative model, which Snorkel will help us easily apply. This will ultimately produce a single set of noise-aware training labels, which we will then use to train an end extraction model in the next notebook. \n",
    "<br>\n",
    "When training the generative model, we'll tune our hyperparamters using a simple grid search.\n",
    "<br>\n",
    "<br>\n",
    "**Parameter Definitions**\n",
    "<br>\n",
    "epochs:     A single pass through all the data in your training set\n",
    "<br>\n",
    "step_size:  The factor by which we update model weights after computing the gradient\n",
    "<br>\n",
    "decay:      The rate our update factor dimishes (decay) over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[1] Testing step_size = 1.00e-05, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.2926829268292683\n",
      "[GenerativeModel] Model saved as <GenerativeModel_0>.\n",
      "[GenerativeModel] Model saved as <GenerativeModel_best>.\n",
      "============================================================\n",
      "[2] Testing step_size = 1.00e-04, decay = 9.00e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.2926829268292683\n",
      "============================================================\n",
      "[3] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.2926829268292683\n",
      "============================================================\n",
      "[4] Testing step_size = 1.00e-05, decay = 9.50e-01, epochs = 100, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.2926829268292683\n",
      "============================================================\n",
      "[5] Testing step_size = 1.00e-03, decay = 9.00e-01, epochs = 50, reg_param = 1.00e-03\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 0.5614035087719298\n",
      "[GenerativeModel] Model saved as <GenerativeModel_4>.\n",
      "[GenerativeModel] Model saved as <GenerativeModel_best>.\n",
      "[GenerativeModel] Model <GenerativeModel_4> loaded.\n",
      "Wall time: 28.3 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step_size</th>\n",
       "      <th>decay</th>\n",
       "      <th>epochs</th>\n",
       "      <th>reg_param</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>Rec.</th>\n",
       "      <th>F-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.90</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.561404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.292683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.90</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.292683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.95</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.292683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.95</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.292683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step_size  decay  epochs  reg_param     Prec.      Rec.       F-1\n",
       "4    0.00100   0.90      50      0.001  0.727273  0.457143  0.561404\n",
       "0    0.00001   0.90     100      0.001  1.000000  0.171429  0.292683\n",
       "1    0.00010   0.90     100      0.001  1.000000  0.171429  0.292683\n",
       "2    0.00001   0.95      50      0.001  1.000000  0.171429  0.292683\n",
       "3    0.00001   0.95     100      0.001  1.000000  0.171429  0.292683"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning import RandomSearch\n",
    "\n",
    "# use random search to optimize the generative model\n",
    "param_ranges = {\n",
    "    'step_size' : [1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'decay'     : [0.9, 0.95],\n",
    "    'epochs'    : [50, 100],\n",
    "    'reg_param' : [1e-3],\n",
    "}\n",
    "\n",
    "model_class_params = {'lf_propensity' : False}\n",
    "\n",
    "searcher = RandomSearch(GenerativeModel, param_ranges, L_train, n=5, model_class_params=model_class_params)\n",
    "%time gen_model, run_stats = searcher.fit(L_dev, L_gold_dev)\n",
    "\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = L_dev.lf_stats(session, L_gold_dev)\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually examine the distribution of predicted training marginals. Ideally, there should get a bimodal distribution with large seperation between each peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20, range=(0.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.457\n",
      "Neg. class accuracy: 0.625\n",
      "Precision            0.727\n",
      "Recall               0.457\n",
      "F1                   0.561\n",
      "----------------------------------------\n",
      "TP: 32 | FP: 12 | TN: 20 | FN: 38\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_marginals = gen_model.marginals(L_dev)\n",
    "_, _, _, _ = gen_model.error_analysis(session, L_dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving our training labels\n",
    "Finally, we'll save the training_marginals, which are our \"noise-aware training labels\", so that we can use them in the next tutorial to train our end extraction model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1641 marginals\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "%time save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel!)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
